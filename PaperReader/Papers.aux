\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{plain}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\HyPL@Entry{2<</S/r>>}
\citation{WangWang2018DeLS}
\citation{Xu2018PADNet}
\citation{Silvia2018Recurrent}
\HyPL@Entry{16<</S/D>>}
\@input{CUDAImageProcessing/CUDAImageProcessing.aux}
\@input{FPGAs/FPGAs.aux}
\citation{toet2016multiscale}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Image Fusion}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Guided Image Filter 2013}{19}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Abstract}{19}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Content}{19}{subsection.3.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Conclusion}{20}{subsection.3.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Multiscale Image Fusion Through Guided Filtering}{20}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Abstract}{20}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Contents}{20}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Conclusion}{22}{subsection.3.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Image Fusion With Guided Filtering}{23}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Abstract}{23}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Contents}{23}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Guided Filter}{23}{section*.22}}
\citation{li2013image}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Fusion Frame}{24}{subsection.3.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Schematic diagram of the proposed image fusion method based on guided filtering.\relax }}{24}{figure.caption.23}}
\newlabel{fig2.1}{{3.1}{24}{Schematic diagram of the proposed image fusion method based on guided filtering.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Conclusion}{24}{subsection.3.3.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Saliency Detection}{25}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Frequency-tuned Salient Region Detection}{25}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Abstract}{25}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Contents}{25}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{Related work}{25}{section*.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Conclusion}{26}{subsection.4.1.3}}
\citation{WangWang2018DeLS}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Semantic SLAM}{27}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}DeLS-3D: Deep Localization and Segmentation with a 2D Semantic Map\cite  {WangWang2018DeLS}}{27}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Abstract}{27}{subsection.5.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Introduction}{27}{subsection.5.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces DeLS Framwork\relax }}{28}{figure.caption.27}}
\newlabel{DeLSFramework}{{5.1}{28}{DeLS Framwork\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Framework}{28}{subsection.5.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Related Work}{28}{subsection.5.1.4}}
\citation{WangWang2018DeLS}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Dataset}{29}{subsection.5.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.6}Localizing camera and Scene Parsing}{29}{subsection.5.1.6}}
\@writefile{toc}{\contentsline {subsubsection}{Render a label map from a camera pose}{29}{section*.28}}
\@writefile{toc}{\contentsline {subsubsection}{Camera Localization rectification with road prior}{30}{section*.29}}
\@writefile{toc}{\contentsline {subsubsection}{Video Parsing with Pose Guidance}{30}{section*.30}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Segment Network in DeLS\relax }}{30}{figure.caption.31}}
\newlabel{SegmentDeLS}{{5.2}{30}{Segment Network in DeLS\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.7}Experiment}{30}{subsection.5.1.7}}
\citation{Xu2018PADNet}
\citation{Wang2018DenseSLAMNet}
\citation{Xu2018PADNet}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.8}Conclusion}{31}{subsection.5.1.8}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}PAD-Net: Multi-Task Guided Prediction-and-Distillation Network for Simultaneous Depth and Scene Parsing \cite  {Xu2018PADNet}}{31}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Abstract}{31}{subsection.5.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Analysis}{31}{subsection.5.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{Effect of Direct Multi-task Learning}{31}{section*.32}}
\@writefile{toc}{\contentsline {subsubsection}{Effect of Multi-modal Distillation}{31}{section*.33}}
\@writefile{toc}{\contentsline {subsubsection}{Importance of Intermediate Supervision and Tasks}{31}{section*.34}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}RNN for Learning Dense Depth and Ego-Motion from Video}{32}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Abstract}{32}{subsection.5.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Introduction \& Related Works}{32}{subsection.5.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Dense SLAM框架\relax }}{33}{figure.caption.35}}
\newlabel{DenseSLAMNet1}{{5.3}{33}{Dense SLAM框架\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Network Architecture}{33}{subsection.5.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Dense SLAM中每一级的细节框架\relax }}{33}{figure.caption.36}}
\newlabel{DenseSLAMNet2}{{5.4}{33}{Dense SLAM中每一级的细节框架\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Training}{34}{subsection.5.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{Loss Function}{34}{section*.37}}
\citation{Xiang2017DARNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Experiments}{35}{subsection.5.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Ablation Studies}{35}{subsection.5.3.6}}
\@writefile{toc}{\contentsline {subsubsection}{Conclusions}{35}{section*.38}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}DA-RNN}{35}{section.5.4}}
\citation{Xu2018PADNet}
\citation{Xu2018PADNet}
\citation{SemanticFusion2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Related Works}{36}{subsection.5.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Methods}{36}{subsection.5.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Experiments}{36}{subsection.5.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Conclusion}{36}{subsection.5.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}SemanticFusion: Dense 3D Semantic Mapping with CNNs}{36}{section.5.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Introduction \& Related Works}{36}{subsection.5.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Method}{37}{subsection.5.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces 粗糙的数据流图\relax }}{37}{figure.caption.39}}
\newlabel{SemanticFusion0}{{5.5}{37}{粗糙的数据流图\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{SLAM Mapping}{37}{section*.40}}
\citation{Meaningful2016}
\@writefile{toc}{\contentsline {subsubsection}{CNN Architecture}{38}{section*.41}}
\@writefile{toc}{\contentsline {subsubsection}{Incremental Semantic Label Fusion}{38}{section*.42}}
\@writefile{toc}{\contentsline {subsubsection}{Map Regularisation}{38}{section*.43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Experiments}{38}{subsection.5.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}总结}{38}{subsection.5.5.4}}
\citation{Felzenszwalb2004}
\citation{Pham2016Geometrically}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Meaningful Maps with Object-Oriented Semantic Mapping}{39}{section.5.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Introduction \& Related Works}{39}{subsection.5.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{Semantic Mapping}{39}{section*.44}}
\@writefile{toc}{\contentsline {subsubsection}{Object Detection and Semantic Segmentation}{39}{section*.45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}Object Oriented Semantic Mapping}{39}{subsection.5.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{Object Detection for Semantic Mapping}{39}{section*.47}}
\@writefile{toc}{\contentsline {subsubsection}{3D Segmentation}{39}{section*.48}}
\@writefile{toc}{\contentsline {subsubsection}{Data Association}{39}{section*.49}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces 算法的几个主要步骤\relax }}{40}{figure.caption.46}}
\newlabel{OrientedMap0}{{5.6}{40}{算法的几个主要步骤\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsubsection}{Object Model Update}{41}{section*.50}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Semantic Mapping 系统概览\relax }}{41}{figure.caption.51}}
\newlabel{OrientedMap1}{{5.7}{41}{Semantic Mapping 系统概览\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsubsection}{Map Generation}{41}{section*.52}}
\citation{Hui2018LiteFlowNet}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}总结}{42}{subsection.5.6.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}LiteFlowNet}{42}{section.5.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.1}背景知识}{42}{subsection.5.7.1}}
\citation{Hui2018LiteFlowNet}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.2}Related Works}{43}{subsection.5.7.2}}
\@writefile{toc}{\contentsline {subsubsection}{Variational Methods}{43}{section*.53}}
\@writefile{toc}{\contentsline {subsubsection}{Machine Learning Methods}{43}{section*.54}}
\@writefile{toc}{\contentsline {subsubsection}{CNN-based Methods}{44}{section*.55}}
\@writefile{toc}{\contentsline {subsubsection}{Establish Point Correspondence}{44}{section*.56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.3}LiteFlowNet}{44}{subsection.5.7.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces LiteFlowNet结构框图\relax }}{44}{figure.caption.57}}
\newlabel{LiteFlowNet0}{{5.8}{44}{LiteFlowNet结构框图\relax }{figure.caption.57}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pyramid Feature Extraction}{45}{section*.58}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Warping (f-warp)}{45}{section*.59}}
\@writefile{toc}{\contentsline {subsubsection}{Cascaded Flow Interface}{45}{section*.60}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces 在NetE中的级联光流推理模块,M:S\relax }}{46}{figure.caption.61}}
\newlabel{LiteFlowNet1}{{5.9}{46}{在NetE中的级联光流推理模块,M:S\relax }{figure.caption.61}{}}
\@writefile{toc}{\contentsline {subsubsection}{Flow Regularization}{47}{section*.62}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.4}Ablation Study}{47}{subsection.5.7.4}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Warping}{47}{section*.63}}
\@writefile{toc}{\contentsline {subsubsection}{Descriptor Matching}{47}{section*.64}}
\@writefile{toc}{\contentsline {subsubsection}{Sub-Pixel Refinement}{47}{section*.65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.5}Regularization}{48}{subsection.5.7.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.6}Conclusion}{48}{subsection.5.7.6}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}小结}{48}{section.5.8}}
\@writefile{toc}{\contentsline {section}{\numberline {5.9}ExFuse: Enhancing Feature Fusion for Semantic Segmentation}{48}{section.5.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9.1}要解决的问题}{48}{subsection.5.9.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9.2}Method}{48}{subsection.5.9.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces ExFusion的实现框图\relax }}{49}{figure.caption.66}}
\newlabel{ExFusion0}{{5.10}{49}{ExFusion的实现框图\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{在底层中加入更多的语义信息}{49}{section*.67}}
\@writefile{toc}{\contentsline {subsubsection}{在高层中加入更多的空间信息}{49}{section*.69}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces 语义嵌入分支的结构图\relax }}{50}{figure.caption.68}}
\newlabel{ExFusion1}{{5.11}{50}{语义嵌入分支的结构图\relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.10}Multi-View Deep Learning for Consistent Semantic Mapping with RGB-D Cameras}{50}{section.5.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10.1}Introduction \& Related Works}{50}{subsection.5.10.1}}
\citation{Xu2018PADNet}
\@writefile{toc}{\contentsline {subsubsection}{Image based Semantic Segmentation}{51}{section*.70}}
\@writefile{toc}{\contentsline {subsubsection}{Semantic SLAM}{51}{section*.71}}
\@writefile{toc}{\contentsline {subsubsection}{Multi-View Semantic Segmentation}{51}{section*.72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10.2}CNN Architecture For Semantic Segmentation}{51}{subsection.5.10.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces 基于Encoder-Decoder CNN的语义分割示意图\relax }}{51}{figure.caption.73}}
\newlabel{MultiView0}{{5.12}{51}{基于Encoder-Decoder CNN的语义分割示意图\relax }{figure.caption.73}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10.3}Multi-View Consistent Learning and Prediction}{52}{subsection.5.10.3}}
\@writefile{toc}{\contentsline {subsubsection}{Multi-view Data Associate Through Warping}{52}{section*.74}}
\@writefile{toc}{\contentsline {subsubsection}{Consistency Through Warp Augmentation}{52}{section*.75}}
\@writefile{toc}{\contentsline {subsubsection}{Consistency Through Bayesian Fusion}{52}{section*.76}}
\@writefile{toc}{\contentsline {subsubsection}{Consistency Through Multi-View Max-Pooling}{52}{section*.77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10.4}Experiments}{53}{subsection.5.10.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10.5}总结}{53}{subsection.5.10.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5.11}MaskFusion}{53}{section.5.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.11.1}背景及相关工作}{53}{subsection.5.11.1}}
\@writefile{toc}{\contentsline {subsubsection}{Dense RGB-D SLAM}{54}{section*.78}}
\@writefile{toc}{\contentsline {subsubsection}{Scene Segmentation \& Semantic Scene Segmentation}{54}{section*.79}}
\@writefile{toc}{\contentsline {subsubsection}{Semantic SLAM \& Dynamic SLAM}{54}{section*.80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.11.2}System Design}{55}{subsection.5.11.2}}
\@writefile{toc}{\contentsline {subsubsection}{System Overview}{55}{section*.81}}
\@writefile{toc}{\contentsline {subsubsection}{Multi-Object SLAM}{55}{section*.83}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Overview of MaskFusion\relax }}{56}{figure.caption.82}}
\newlabel{MaskFusion0}{{5.13}{56}{Overview of MaskFusion\relax }{figure.caption.82}{}}
\@writefile{toc}{\contentsline {subsubsection}{Segmentation}{57}{section*.84}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.11.3}Evaluation}{57}{subsection.5.11.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.11.4}总结}{57}{subsection.5.11.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.12}小结 2}{58}{section.5.12}}
\@writefile{toc}{\contentsline {section}{\numberline {5.13}CNN-SLAM}{58}{section.5.13}}
\@writefile{toc}{\contentsline {section}{\numberline {5.14}图像语义分割之FCN和CRF}{58}{section.5.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces 图像分割的算法框架\relax }}{58}{figure.caption.85}}
\newlabel{ImageSegmentFrame0}{{5.14}{58}{图像分割的算法框架\relax }{figure.caption.85}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.14.1}前端FCN}{59}{subsection.5.14.1}}
\@writefile{toc}{\contentsline {subsubsection}{FCN}{59}{section*.86}}
\@writefile{toc}{\contentsline {subsubsection}{SegNet/DecovNet}{59}{section*.87}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.14.2}DeepLab}{59}{subsection.5.14.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Atrous Convolution 示意图\relax }}{60}{figure.caption.88}}
\newlabel{DeepLabAtrousConvolution0}{{5.15}{60}{Atrous Convolution 示意图\relax }{figure.caption.88}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Atrous Convolution中的感受野变化 示意图\relax }}{60}{figure.caption.89}}
\newlabel{DeepLabAtrousConvolution1}{{5.16}{60}{Atrous Convolution中的感受野变化 示意图\relax }{figure.caption.89}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.14.3}后端优化CRF/MRF}{61}{subsection.5.14.3}}
\@writefile{toc}{\contentsline {subsubsection}{全连接CRF， DenseCRF}{61}{section*.90}}
\@writefile{toc}{\contentsline {subsubsection}{CRFasRNN}{61}{section*.91}}
\@writefile{toc}{\contentsline {subsubsection}{马尔科夫随机场， MRF}{61}{section*.92}}
\@writefile{toc}{\contentsline {subsubsection}{高斯条件随机场， G-CRF}{61}{section*.93}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.14.4}小结}{61}{subsection.5.14.4}}
\citation{ReSeg2015}
\@writefile{toc}{\contentsline {section}{\numberline {5.15}Learning Deconvolution Network for Semantic}{62}{section.5.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces 论文提出的神经网络结构\relax }}{62}{figure.caption.94}}
\newlabel{LearnDeconv0}{{5.17}{62}{论文提出的神经网络结构\relax }{figure.caption.94}{}}
\@writefile{toc}{\contentsline {subsubsection}{Instance-wise Segmentation}{63}{section*.95}}
\@writefile{toc}{\contentsline {section}{\numberline {5.16}ReSeg 2015}{63}{section.5.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.16.1}背景 \& 相关工作}{63}{subsection.5.16.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.16.2}Model Description}{63}{subsection.5.16.2}}
\@writefile{toc}{\contentsline {subsubsection}{Recurrent layer}{63}{section*.96}}
\@writefile{toc}{\contentsline {subsubsection}{Upsampling layer}{63}{section*.98}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces ReNet layer结构\relax }}{64}{figure.caption.97}}
\newlabel{ReSeg0}{{5.18}{64}{ReNet layer结构\relax }{figure.caption.97}{}}
\citation{U-Net2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.16.3}实验结果}{65}{subsection.5.16.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.16.4}总结}{65}{subsection.5.16.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.17}U-Net}{65}{section.5.17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.17.1}Network Architecture}{65}{subsection.5.17.1}}
\citation{Fcn2014}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces U-Net结构示意图\relax }}{66}{figure.caption.99}}
\newlabel{U-Net0}{{5.19}{66}{U-Net结构示意图\relax }{figure.caption.99}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.17.2}Conclusion}{66}{subsection.5.17.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.17.3}补充}{66}{subsection.5.17.3}}
\citation{SemanticVisualLocalization2017}
\@writefile{toc}{\contentsline {section}{\numberline {5.18}Semantic Visual Localization}{67}{section.5.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.18.1}背景 \& 相关工作}{67}{subsection.5.18.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.18.2}Semantic Visual Localization}{68}{subsection.5.18.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Generative Descriptor Learning的示意图\relax }}{69}{figure.caption.100}}
\newlabel{SemanticVisualLoc0}{{5.20}{69}{Generative Descriptor Learning的示意图\relax }{figure.caption.100}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.18.3}Experiments}{69}{subsection.5.18.3}}
\citation{scona2018staticfusion}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.18.4}Conclusions}{70}{subsection.5.18.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.19}小结3}{70}{section.5.19}}
\@writefile{toc}{\contentsline {section}{\numberline {5.20}StaticFusion}{70}{section.5.20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.20.1}背景}{70}{subsection.5.20.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.20.2}动态场景下SLAM系统的相关工作}{70}{subsection.5.20.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.20.3}Framework和Notation}{71}{subsection.5.20.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces StaticFusion算法的三个主要流程\relax }}{71}{figure.caption.101}}
\newlabel{StaticFusion0}{{5.21}{71}{StaticFusion算法的三个主要流程\relax }{figure.caption.101}{}}
\citation{marvin2018crf}
\@writefile{toc}{\contentsline {subsubsection}{第二步的计算}{72}{section*.102}}
\@writefile{toc}{\contentsline {section}{\numberline {5.21}Convolutional CRFs for Semantic Segmentation}{72}{section.5.21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.21.1}背景 \& 相关工作}{72}{subsection.5.21.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.21.2}Fully Connected CRFs}{73}{subsection.5.21.2}}
\@writefile{toc}{\contentsline {subsubsection}{Full CRF的Mean field inference}{74}{section*.103}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.22}{\ignorespaces Mean field inference算法步骤\relax }}{74}{figure.caption.104}}
\newlabel{ConvCRF0}{{5.22}{74}{Mean field inference算法步骤\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.21.3}Convolutional CRFs}{74}{subsection.5.21.3}}
\@writefile{toc}{\contentsline {subsubsection}{Efficient Message Passing in ConvCRFs }{74}{section*.105}}
\citation{runz2017co}
\citation{senet2017hu}
\@writefile{toc}{\contentsline {subsubsection}{Additional implementation details}{75}{section*.106}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.21.4}总结}{75}{subsection.5.21.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.22}Co-Fusion}{75}{section.5.22}}
\@writefile{toc}{\contentsline {section}{\numberline {5.23}Squeeze-and-Excitation Networks}{75}{section.5.23}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.23}{\ignorespaces SENet结构示意图\relax }}{76}{figure.caption.107}}
\newlabel{SENet0}{{5.23}{76}{SENet结构示意图\relax }{figure.caption.107}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.24}Deep Multi-scale Architectures For Monocular Depth Estimation}{76}{section.5.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.24.1}背景与相关工作}{76}{subsection.5.24.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.25}Depth Map Prediction from a single image usign a multi-Scale Deep Network}{77}{section.5.25}}
\citation{maskrcnn2017he}
\@writefile{lof}{\contentsline {figure}{\numberline {5.24}{\ignorespaces 网络结构示意图\relax }}{78}{figure.caption.108}}
\newlabel{DepthPrediction2014_0}{{5.24}{78}{网络结构示意图\relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.26}Mask R-CNN}{78}{section.5.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.25}{\ignorespaces Mask RCNN示意图，在class box的基础上增加了预测mask的分支。\relax }}{79}{figure.caption.109}}
\newlabel{MaskRCNN0}{{5.25}{79}{Mask RCNN示意图，在class box的基础上增加了预测mask的分支。\relax }{figure.caption.109}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.26.1}研究现状与相关背景}{79}{subsection.5.26.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.26.2}Mask RCNN}{79}{subsection.5.26.2}}
\citation{hu2017learning}
\@writefile{lof}{\contentsline {figure}{\numberline {5.26}{\ignorespaces ROI Align的示意图, 如何将region of interest的原始图像和特征图精确对齐？\relax }}{80}{figure.caption.110}}
\newlabel{MaskRCNN1_ROIAlign0}{{5.26}{80}{ROI Align的示意图, 如何将region of interest的原始图像和特征图精确对齐？\relax }{figure.caption.110}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.26.3}实验}{80}{subsection.5.26.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.26.4}总结}{80}{subsection.5.26.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.27}Learning to segment every thing}{80}{section.5.27}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.27}{\ignorespaces 论文的整体结构，包括Weight Transfer 结构\relax }}{81}{figure.caption.111}}
\newlabel{MaskXRCNN0}{{5.27}{81}{论文的整体结构，包括Weight Transfer 结构\relax }{figure.caption.111}{}}
\citation{liu2018path}
\citation{ren2017end}
\citation{li2016fully}
\@writefile{toc}{\contentsline {section}{\numberline {5.28}Path aggregation network for instance segmentation}{82}{section.5.28}}
\@writefile{toc}{\contentsline {section}{\numberline {5.29}End-to-End Instance Segmentation with Recurrent Attention}{82}{section.5.29}}
\@writefile{toc}{\contentsline {section}{\numberline {5.30}Fully Convolutional Instance-aware Semantic Segmentation}{82}{section.5.30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.30.1}背景与相关现状}{82}{subsection.5.30.1}}
\citation{iglovikov2018ternausnetv2}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.30.2}Our Approach}{83}{subsection.5.30.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.31}TernausNetV2: Fully Convolutional Network for Instance Segmentation}{83}{section.5.31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.1}背景及相关工作}{83}{subsection.5.31.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.2}Model}{83}{subsection.5.31.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.3}Training}{83}{subsection.5.31.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.4}常用数据集}{84}{subsection.5.31.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.5}KITTI}{84}{subsection.5.31.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.6}官网资源介绍}{84}{subsection.5.31.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.28}{\ignorespaces KITTI官网截图\relax }}{84}{figure.caption.112}}
\newlabel{KITTI0}{{5.28}{84}{KITTI官网截图\relax }{figure.caption.112}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.7}详述}{85}{subsection.5.31.7}}
\@writefile{toc}{\contentsline {subsubsection}{组织形式}{85}{section*.113}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.29}{\ignorespaces 早期的数据文件组织格式\relax }}{85}{figure.caption.114}}
\newlabel{KITTI1}{{5.29}{85}{早期的数据文件组织格式\relax }{figure.caption.114}{}}
\@writefile{toc}{\contentsline {subsubsection}{Development Kit}{86}{section*.115}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.8}Cityscape}{86}{subsection.5.31.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.31.9}TUM}{86}{subsection.5.31.9}}
\@writefile{toc}{\contentsline {section}{\numberline {5.32}实例分割-图像分割2018.06.11博客总结}{86}{section.5.32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.32.1}Mask R-CNN狙击目标实例分割}{86}{subsection.5.32.1}}
\@writefile{toc}{\contentsline {subsubsection}{什么是实例分割}{86}{section*.116}}
\@writefile{toc}{\contentsline {subsubsection}{Mask RCNN介绍}{86}{section*.117}}
\@writefile{toc}{\contentsline {subsubsection}{Mask RCNN的工作机理}{87}{section*.118}}
\@writefile{toc}{\contentsline {subsubsection}{Tensorflow + Keras实现实例分割}{87}{section*.119}}
\@writefile{toc}{\contentsline {section}{\numberline {5.33}无需Proposal的实例分割论文}{87}{section.5.33}}
\citation{gupta2014learning}
\citation{eitel2015multimodal}
\@writefile{toc}{\contentsline {section}{\numberline {5.34}Learning Rich Features from RGB-D Images for Object Detection and Segmentation}{88}{section.5.34}}
\@writefile{toc}{\contentsline {section}{\numberline {5.35}Multimodal Deep Learning for Robust RGB-D Object Recognition}{88}{section.5.35}}
\@writefile{toc}{\contentsline {section}{\numberline {5.36}3D Graph Neural Networks for RGBD Semantic Segmentation}{89}{section.5.36}}
\@writefile{toc}{\contentsline {section}{\numberline {5.37}RefineNet}{89}{section.5.37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.37.1}引言中的重要几点}{89}{subsection.5.37.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.37.2}算法思想}{90}{subsection.5.37.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.37.3}实验部分}{90}{subsection.5.37.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.37.4}小结}{90}{subsection.5.37.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.38}Residual Attention Network For Image Classification}{90}{section.5.38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.38.1}背景及相关工作}{90}{subsection.5.38.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.38.2}Residual Attention Network}{91}{subsection.5.38.2}}
\@writefile{toc}{\contentsline {subsubsection}{Attention Residual Learning}{91}{section*.120}}
\@writefile{toc}{\contentsline {subsubsection}{Soft Mask Branch}{92}{section*.121}}
\@writefile{toc}{\contentsline {subsubsection}{Spatial Attention And Channel Attention}{92}{section*.122}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.38.3}实验}{93}{subsection.5.38.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.38.4}总结}{93}{subsection.5.38.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.39}Object-based RGBD Image Co-segmentation with Mutex Constraint}{93}{section.5.39}}
\@writefile{toc}{\contentsline {section}{\numberline {5.40}RedNet: Residual Encoder-Decoder Network for indoor .RGB-D Semantic Segmentation}{94}{section.5.40}}
\@writefile{toc}{\contentsline {section}{\numberline {5.41}RDFNet: RGB-D Multi-level Residual Feature fusion for Indoor Sematnic Segmentation}{94}{section.5.41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.42}Progressively Complementarity-aware Fusion Network for RGB-D Salient Object Detection}{94}{section.5.42}}
\@writefile{toc}{\contentsline {section}{\numberline {5.43}Semantic-Guided Multi-level RGB-D Feature Fusion for Indoor Semantic segmentation}{94}{section.5.43}}
\@writefile{toc}{\contentsline {section}{\numberline {5.44}Learning Common and Specific Features for RGB-D Semantic Segmentation with Deconvolutional Networks}{94}{section.5.44}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Open Set Recognition}{95}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}GAN}{95}{section.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}GAN 原理笔记}{95}{subsection.6.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{GAN原理}{95}{section*.123}}
\@writefile{toc}{\contentsline {subsubsection}{GAN公式}{96}{section*.124}}
\newlabel{GAN:LossFunction0}{{6.5}{96}{GAN公式}{equation.6.1.5}{}}
\newlabel{GAN:ObjectFunction0}{{6.6}{96}{GAN公式}{equation.6.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{训练过程}{96}{section*.125}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces GAN训练过程\relax }}{96}{figure.caption.126}}
\newlabel{GAN:Training0}{{6.1}{96}{GAN训练过程\relax }{figure.caption.126}{}}
\citation{Goodfellow2014GAN}
\newlabel{GAN:ObjectFunction1}{{6.8}{97}{训练过程}{equation.6.1.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{Loss Function中的两个小问题}{97}{section*.127}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}从头开始GAN}{97}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}定义}{98}{subsection.6.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}DCGAN： Deep Convolution GAN}{98}{subsection.6.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}CGAN: Conditional Generative Adversarial Nets}{99}{subsection.6.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces CGAN示意图，在G、N网络中新增了数据y\relax }}{99}{figure.caption.128}}
\newlabel{CGAN0}{{6.2}{99}{CGAN示意图，在G、N网络中新增了数据y\relax }{figure.caption.128}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}InfoGAN}{99}{subsection.6.2.4}}
\citation{Goodfellow2014GAN}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Generative Adversarial Nets}{100}{section.6.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Towards Open Set Deep Networks}{100}{section.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Introduction \& Related Works}{100}{subsection.6.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Probability Models for Open Set Recognition}{100}{section.6.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}背景及相关工作}{101}{subsection.6.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Meta Recognition}{101}{section.6.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}该死的Fisher-Tippet Theorem}{101}{subsection.6.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{Extreme Value Theory}{102}{section*.129}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}Weibull Distribution}{102}{subsection.6.6.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}MXNet}{103}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}MXNet System Overview}{103}{section.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}MXNet System Architecture}{103}{subsection.7.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}MXNet System Components}{104}{subsection.7.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{Execution Engine}{104}{section*.130}}
\@writefile{toc}{\contentsline {subsubsection}{Operators in MXNet}{104}{section*.131}}
\@writefile{toc}{\contentsline {subsubsection}{Operator Interface}{104}{section*.132}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.1}Image colvotion based on Shared memory and Apron}{104}{lstlisting.7.1}}
\@writefile{toc}{\contentsline {subsubsection}{Operator Property}{105}{section*.133}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.2}Image colvotion based on Shared memory and Apron}{105}{lstlisting.7.2}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.3}Image colvotion based on Shared memory and Apron}{106}{lstlisting.7.3}}
\@writefile{toc}{\contentsline {subsubsection}{Create an Operator from the Operator Property}{106}{section*.134}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Optimizing Memory Consumption in DL}{106}{section.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Computation Graph}{106}{subsection.7.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces The implicitly \& explicitly back-propagation on Graph\relax }}{107}{figure.caption.135}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Dependencies can be found quickly.\relax }}{107}{figure.caption.136}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Different backward path from forward path.\relax }}{108}{figure.caption.137}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}What Can be Optimized?}{108}{subsection.7.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{In-place Operations}{108}{section*.138}}
\@writefile{toc}{\contentsline {subsubsection}{Standard Memory Sharing}{108}{section*.139}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Standard Memory sharing between \textbf  {B} \& the result of \textbf  {E}.\relax }}{108}{figure.caption.140}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Memory Allocation Algorithm}{109}{subsection.7.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Standard Memory sharing between \textbf  {B} \& the result of \textbf  {E}.\relax }}{109}{figure.caption.141}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Standard Memory sharing between \textbf  {B} \& the result of \textbf  {E}.\relax }}{110}{figure.caption.142}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}Static vs. Dynamic Allocation}{110}{subsection.7.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.5}Memory Allocation for Parallel Operations}{110}{subsection.7.2.5}}
\@writefile{toc}{\contentsline {subsubsection}{Be Correct and Safe First}{110}{section*.144}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Standard Memory sharing between \textbf  {B} \& the result of \textbf  {E}.\relax }}{111}{figure.caption.143}}
\@writefile{toc}{\contentsline {subsubsection}{Try to Allow More Parallelization}{111}{section*.145}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces Color the longest paths in the Graph.\relax }}{111}{figure.caption.146}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.6}How Much Can we Save ?}{112}{subsection.7.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.7}References}{112}{subsection.7.2.7}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Deep Learning Programming Style}{112}{section.7.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Symbolic vs. Imperative Program}{112}{subsection.7.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Imperative Programs Tend to be More Flexible}{112}{subsection.7.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces Operation Folding示意图。\relax }}{113}{figure.caption.147}}
\newlabel{Symbolic1}{{7.9}{113}{Operation Folding示意图。\relax }{figure.caption.147}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}Symbolic Programs Tend to be More Efficient}{113}{subsection.7.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.4}Case Study: Backprop and AutoDiff}{113}{subsection.7.3.4}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.4}Image colvotion based on Shared memory and Apron}{113}{lstlisting.7.4}}
\@writefile{toc}{\contentsline {subsubsection}{基于命令式编程的自动求导}{113}{section*.148}}
\@writefile{toc}{\contentsline {subsubsection}{基于符号式编程的自动求导}{114}{section*.149}}
\@writefile{toc}{\contentsline {subsubsection}{Analysis}{114}{section*.150}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.5}Model Checkpoint}{114}{subsection.7.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.6}Big vs. Small Operations}{114}{subsection.7.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.7}Mix The Approaches}{115}{subsection.7.3.7}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Dependency Engine for Deep Learning}{116}{section.7.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Problems in Dependency Scheduling}{116}{subsection.7.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{Design a Generic Dependency Engine}{116}{section*.151}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces 第一步，给变量分配tag\relax }}{116}{figure.caption.152}}
\newlabel{Tag1}{{7.10}{116}{第一步，给变量分配tag\relax }{figure.caption.152}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.11}{\ignorespaces 把相应的Function Closure push进依赖分析引擎\relax }}{117}{figure.caption.153}}
\newlabel{Tag2}{{7.11}{117}{把相应的Function Closure push进依赖分析引擎\relax }{figure.caption.153}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Implementing the Generic Dependency Engine}{117}{subsection.7.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.12}{\ignorespaces 一个具体的例子\relax }}{117}{figure.caption.154}}
\newlabel{Tag3.png}{{7.12}{117}{一个具体的例子\relax }{figure.caption.154}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.3}Discussion}{118}{subsection.7.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Designing Efficient Data Loaders for DL}{118}{section.7.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}Design Insight}{118}{subsection.7.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{Data Preparation}{118}{section*.155}}
\@writefile{toc}{\contentsline {subsubsection}{Data Loading}{118}{section*.156}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.13}{\ignorespaces Binary recordIO数据结构\relax }}{119}{figure.caption.157}}
\newlabel{recordIO1}{{7.13}{119}{Binary recordIO数据结构\relax }{figure.caption.157}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Data Format}{119}{subsection.7.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.14}{\ignorespaces Binary recordIO的一个例子\relax }}{119}{figure.caption.158}}
\newlabel{recordIO2}{{7.14}{119}{Binary recordIO的一个例子\relax }{figure.caption.158}{}}
\@writefile{toc}{\contentsline {subsubsection}{Access Arbitrary Parts of Data}{120}{section*.159}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.3}Data Loading and Preprocessing}{120}{subsection.7.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{Loading and Preprocessing on the Fly}{120}{section*.160}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.15}{\ignorespaces 并行预处理例子\relax }}{120}{figure.caption.161}}
\newlabel{loadingData1}{{7.15}{120}{并行预处理例子\relax }{figure.caption.161}{}}
\@writefile{toc}{\contentsline {subsubsection}{Hide IO Cost Using Threadediter}{120}{section*.162}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.4}MXNet IO Python Interface}{120}{subsection.7.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.16}{\ignorespaces 数据预取的示意图，借助Buffer来实现\relax }}{121}{figure.caption.163}}
\newlabel{loadingData2}{{7.16}{121}{数据预取的示意图，借助Buffer来实现\relax }{figure.caption.163}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Except Handling in MXNet}{121}{section.7.6}}
\@writefile{toc}{\contentsline {subsubsection}{Exception Handling for Iterators}{122}{section*.164}}
\@writefile{toc}{\contentsline {subsubsection}{Except Handling for Operators}{122}{section*.165}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}MXNet-Gluon创建模型}{122}{section.7.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.1}模型构造}{122}{subsection.7.7.1}}
\@writefile{toc}{\contentsline {subsubsection}{两种稍微不同的实现}{122}{section*.166}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.5}{自定义模型，方式一}， label}{122}{lstlisting.7.5}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.6}{自定义模型，方式二}， label}{123}{lstlisting.7.6}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.7}{自定义模型VGG11，方式三}， label}{123}{lstlisting.7.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.2}自定义层}{124}{subsection.7.7.2}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.8}{自定义层，方式一}， label}{124}{lstlisting.7.8}}
\@writefile{toc}{\contentsline {subsubsection}{带参数的自定义层}{124}{section*.167}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.9}{带参数的自定义层，方式一}， label}{124}{lstlisting.7.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.3}实际例子}{124}{subsection.7.7.3}}
\@writefile{toc}{\contentsline {subsubsection}{ResNet}{124}{section*.168}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.10}ResNet using Gluon}{125}{lstlisting.7.10}}
\@writefile{toc}{\contentsline {subsubsection}{DenseNet}{126}{section*.169}}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}MXNet中的Deconvolution}{126}{section.7.8}}
\@writefile{toc}{\contentsline {section}{\numberline {7.9}MXNet读取训练数据}{126}{section.7.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.1}使用mx.io读取数据}{127}{subsection.7.9.1}}
\@writefile{toc}{\contentsline {subsubsection}{从内存中读取}{127}{section*.170}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.11}train\_mnist.py例子}{127}{lstlisting.7.11}}
\@writefile{toc}{\contentsline {subsubsection}{从.csv文件中读取数据}{128}{section*.171}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.12}Read .csv 数据}{128}{lstlisting.7.12}}
\@writefile{toc}{\contentsline {subsubsection}{使用mx.io.ImageRecordIter接口，需要定制KVStore}{128}{section*.172}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.2}常用的系统提供的接口函数}{129}{subsection.7.9.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.3}使用mx.image读取数据}{129}{subsection.7.9.3}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.13}mx.image使用示例}{129}{lstlisting.7.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.4}使用Gluon接口读取数据}{130}{subsection.7.9.4}}
\@writefile{toc}{\contentsline {subsubsection}{产生Dataset}{130}{section*.173}}
\@writefile{toc}{\contentsline {subsubsection}{产生Mini-batch iterator}{131}{section*.174}}
\@writefile{toc}{\contentsline {section}{\numberline {7.10}Gluon中的数据结构}{131}{section.7.10}}
\@writefile{toc}{\contentsline {section}{\numberline {7.11}MXNet中的Confusing参数}{132}{section.7.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.1}mx.symbol.reshape}{132}{subsection.7.11.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.2}mx.symbol.transpose}{132}{subsection.7.11.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7.12}UpSample In MXNet}{133}{section.7.12}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.14}UpSampling的一个例子}{133}{lstlisting.7.14}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.15}UpSample例子2}{134}{lstlisting.7.15}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.16}UpSampling的一个例子}{135}{lstlisting.7.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.12.1}总结}{135}{subsection.7.12.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.13}MXNet中设置层的学习率}{135}{section.7.13}}
\@writefile{toc}{\contentsline {section}{\numberline {7.14}SoftmaxCrossEntropyLoss释疑}{135}{section.7.14}}
\@writefile{toc}{\contentsline {section}{\numberline {7.15}MXNet中的3D CNN}{136}{section.7.15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.15.1}应该怎么理解3D CNN}{136}{subsection.7.15.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.16}向MXNet添加新的操作}{136}{section.7.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.16.1}添加新的Operator}{136}{subsection.7.16.1}}
\@writefile{toc}{\contentsline {subsubsection}{自定义Op}{136}{section*.175}}
\@writefile{toc}{\contentsline {subsubsection}{CustomOp类}{137}{section*.176}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.17}基于CustomOp的Softmax}{137}{lstlisting.7.17}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.18}第二步，基于CustomOpProp的SoftmaxProp类}{138}{lstlisting.7.18}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.19}第二步，基于CustomOpProp的SoftmaxProp类}{138}{lstlisting.7.19}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.20}第二步，基于CustomOpProp的SoftmaxProp类}{139}{lstlisting.7.20}}
\@writefile{toc}{\contentsline {subsubsection}{PythonOp类}{139}{section*.177}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.16.2}添加新的Layer}{139}{subsection.7.16.2}}
\@writefile{toc}{\contentsline {subsubsection}{如何创建新的网络层-CSDN}{140}{section*.178}}
\@writefile{toc}{\contentsline {subsubsection}{MXNet添加新层-CSDN}{141}{section*.179}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.21}在mshadow\_op.h里面添加结构体}{141}{lstlisting.7.21}}
\@writefile{toc}{\contentsline {section}{\numberline {7.17}关于MXNet里面的register修饰符}{142}{section.7.17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.17.1}调用顺序-CSDN博客}{142}{subsection.7.17.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.17.2}Python中的装饰器之register}{142}{subsection.7.17.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}GPU Optimization in DL}{143}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}In-Place Activated BatchNorm for Memory-Optimized Training of DNNs}{143}{section.8.1}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Training deep nets with sublinear memory cost}{143}{section.8.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Memory-efficient backpropagation through time}{143}{section.8.3}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}The Reversible Residual Network: Backpropagation Without Storing Activations}{143}{section.8.4}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}}{143}{section.8.5}}
\citation{marvin2018crf}
\citation{chen18iterative}
\citation{YuKoltun2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Tips in DL}{145}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Enlarge the FOV}{145}{section.9.1}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Upsampling}{145}{section.9.2}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Multiscale Ability}{146}{section.9.3}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Dilated Convolution}{146}{section.9.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Dilated Convolution示意图\relax }}{146}{figure.caption.180}}
\newlabel{DilatedConv1}{{9.1}{146}{Dilated Convolution示意图\relax }{figure.caption.180}{}}
\citation{Fcn2014}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces Dilated Convolution在WaveNet中的应用示意图\relax }}{147}{figure.caption.181}}
\newlabel{WaveNet1}{{9.2}{147}{Dilated Convolution在WaveNet中的应用示意图\relax }{figure.caption.181}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Deconvolutional Network}{147}{section.9.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.1}Convolutional Spare Coding}{147}{subsection.9.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.2}CNN可视化}{147}{subsection.9.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.3}Upsampling}{148}{subsection.9.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.4}补充}{148}{subsection.9.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.5}Deconvolution与Upsample的区别}{148}{subsection.9.5.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces Transpose Convolution过程示意图\relax }}{148}{figure.caption.182}}
\newlabel{Deconvolution0}{{9.3}{148}{Transpose Convolution过程示意图\relax }{figure.caption.182}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9.1}Bilinear filter initializer in MXNet}{149}{lstlisting.9.1}}
\@writefile{toc}{\contentsline {subsubsection}{理解深度学习中的Deconvolution Networks}{149}{section*.183}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces 一个例子，用于卷积操作说明\relax }}{150}{figure.caption.184}}
\newlabel{Deconvolution1}{{9.4}{150}{一个例子，用于卷积操作说明\relax }{figure.caption.184}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces 卷积操作时的矩阵形式\relax }}{150}{figure.caption.185}}
\newlabel{Deconvolution2}{{9.5}{150}{卷积操作时的矩阵形式\relax }{figure.caption.185}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.6}Deconvolution输出的大小计算}{150}{subsection.9.5.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.7}Conv2DTranspose用于成倍的提高分辨率的时候}{150}{subsection.9.5.7}}
\@writefile{toc}{\contentsline {section}{\numberline {9.6}Dilated Network与Deconv Network之间的区别}{151}{section.9.6}}
\@writefile{toc}{\contentsline {section}{\numberline {9.7}目标检测中的mAP的含义}{151}{section.9.7}}
\newlabel{PrecisionC1}{{9.7}{151}{目标检测中的mAP的含义}{section.9.7}{}}
\newlabel{PrecisionC2}{{9.7}{151}{目标检测中的mAP的含义}{section.9.7}{}}
\citation{Xu2018PADNet}
\citation{Mehta2018OD200}
\citation{Xu2018PADNet}
\citation{Xu2018PADNet}
\citation{Xu2018PADNet}
\citation{Mehta2018OD200}
\newlabel{PrecisionC3}{{9.7}{152}{目标检测中的mAP的含义}{section.9.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.8}统计学习方法}{152}{section.9.8}}
\@writefile{toc}{\contentsline {section}{\numberline {9.9}Distillation Module}{152}{section.9.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces 三种不同的Distillation Module\relax }}{152}{figure.caption.186}}
\newlabel{ThreeDistillationModules1}{{9.6}{152}{三种不同的Distillation Module\relax }{figure.caption.186}{}}
\citation{Silvia2018Recurrent}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.9.1}Knowledge Distillation}{153}{subsection.9.9.1}}
\@writefile{toc}{\contentsline {subsubsection}{什么是Distilling the knowledge}{153}{section*.187}}
\@writefile{toc}{\contentsline {subsubsection}{Disilling the knowledge in a Neural Network}{153}{section*.188}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.9.2}Recurrent Knowledge Distillation \cite  {Silvia2018Recurrent}}{153}{subsection.9.9.2}}
\@writefile{toc}{\contentsline {section}{\numberline {9.10}光流估计中的Average end-point error}{153}{section.9.10}}
\@writefile{toc}{\contentsline {section}{\numberline {9.11}CNN中的卷及方式汇总}{153}{section.9.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.11.1}Inception}{153}{subsection.9.11.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces Inception卷积结构\relax }}{154}{figure.caption.189}}
\newlabel{Inception0}{{9.7}{154}{Inception卷积结构\relax }{figure.caption.189}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.11.2}空洞卷积, Dilation}{154}{subsection.9.11.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.11.3}深度可分离卷积, Depthwise Separable Convolution}{154}{subsection.9.11.3}}
\newlabel{Inception1}{{9.8(a)}{155}{Subfigure 9 9.8(a)}{subfigure.9.8.1}{}}
\newlabel{sub@Inception1}{{(a)}{155}{Subfigure 9 9.8(a)\relax }{subfigure.9.8.1}{}}
\newlabel{DepthwiseSeparable0}{{9.8(b)}{155}{Subfigure 9 9.8(b)}{subfigure.9.8.2}{}}
\newlabel{sub@DepthwiseSeparable0}{{(b)}{155}{Subfigure 9 9.8(b)\relax }{subfigure.9.8.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces Inception结构与Depthwise Separable Convolution结构对比\relax }}{155}{figure.caption.190}}
\newlabel{InceptionAndDepthwise0}{{9.8}{155}{Inception结构与Depthwise Separable Convolution结构对比\relax }{figure.caption.190}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {简化的Inception}}}{155}{figure.caption.190}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Depthwise Separable Convolution的示意图， 可以看出来，与Inception很像。}}}{155}{figure.caption.190}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces Channel分组的极限版本\relax }}{156}{figure.caption.191}}
\newlabel{DepthwiseSeparable1}{{9.9}{156}{Channel分组的极限版本\relax }{figure.caption.191}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.11.4}可变性卷积}{156}{subsection.9.11.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces Deformable Convolution示意图\relax }}{157}{figure.caption.192}}
\newlabel{DeformableConv0}{{9.10}{157}{Deformable Convolution示意图\relax }{figure.caption.192}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.11}{\ignorespaces Deformable Convolution的实现示意图\relax }}{157}{figure.caption.193}}
\newlabel{DeformableConv1}{{9.11}{157}{Deformable Convolution的实现示意图\relax }{figure.caption.193}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.11.5}特征重标定卷积}{158}{subsection.9.11.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.12}{\ignorespaces Squeeze-and-Excitation Block示意图\relax }}{158}{figure.caption.194}}
\newlabel{SENetConv0}{{9.12}{158}{Squeeze-and-Excitation Block示意图\relax }{figure.caption.194}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.11.6}小结-比较}{158}{subsection.9.11.6}}
\newlabel{SEInception0}{{9.13(a)}{159}{Subfigure 9 9.13(a)}{subfigure.9.13.1}{}}
\newlabel{sub@SEInception0}{{(a)}{159}{Subfigure 9 9.13(a)\relax }{subfigure.9.13.1}{}}
\newlabel{SEResNet0}{{9.13(b)}{159}{Subfigure 9 9.13(b)}{subfigure.9.13.2}{}}
\newlabel{sub@SEResNet0}{{(b)}{159}{Subfigure 9 9.13(b)\relax }{subfigure.9.13.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.13}{\ignorespaces SENet与Inception以及ResNet结合的示意图\relax }}{159}{figure.caption.195}}
\newlabel{SENetConv1}{{9.13}{159}{SENet与Inception以及ResNet结合的示意图\relax }{figure.caption.195}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {SE-Inception Module}}}{159}{figure.caption.195}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {SE-ResNet Module}}}{159}{figure.caption.195}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.14}{\ignorespaces 不同卷积策略的比较\relax }}{159}{figure.caption.196}}
\newlabel{Conv0}{{9.14}{159}{不同卷积策略的比较\relax }{figure.caption.196}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.12}全连接与卷积的异同}{160}{section.9.12}}
\@writefile{toc}{\contentsline {section}{\numberline {9.13}Pooling}{160}{section.9.13}}
\@writefile{toc}{\contentsline {subsubsection}{Global Average Pooling}{160}{section*.197}}
\@writefile{toc}{\contentsline {subsubsection}{Unpooling}{160}{section*.198}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.15}{\ignorespaces Unpooling示意图\relax }}{160}{figure.caption.199}}
\newlabel{Unpooling0}{{9.15}{160}{Unpooling示意图\relax }{figure.caption.199}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.14}Local Response Normalization}{161}{section.9.14}}
\@writefile{toc}{\contentsline {subsubsection}{到底什么是LRN}{161}{section*.200}}
\@writefile{toc}{\contentsline {subsubsection}{如何实现LRN}{161}{section*.201}}
\@writefile{toc}{\contentsline {section}{\numberline {9.15}CNN中感受野的计算}{162}{section.9.15}}
\@writefile{toc}{\contentsline {subsubsection}{具体的例子}{162}{section*.202}}
\@writefile{toc}{\contentsline {subsubsection}{Stride的计算}{163}{section*.203}}
\@writefile{toc}{\contentsline {subsubsection}{专业的计算}{163}{section*.204}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.16}{\ignorespaces 文章的总结与说明\relax }}{164}{figure.caption.205}}
\newlabel{PerceptionField1}{{9.16}{164}{文章的总结与说明\relax }{figure.caption.205}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.17}{\ignorespaces 二维图像像素编号示意图\relax }}{165}{figure.caption.206}}
\newlabel{PerceptionField0}{{9.17}{165}{二维图像像素编号示意图\relax }{figure.caption.206}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.16}神经网络中的初始化}{166}{section.9.16}}
\@writefile{toc}{\contentsline {subsubsection}{回答一}{166}{section*.207}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.16.1}Xavier}{166}{subsection.9.16.1}}
\@writefile{toc}{\contentsline {section}{\numberline {9.17}计算图的后向传播计算}{167}{section.9.17}}
\@writefile{toc}{\contentsline {subsubsection}{简单的说明}{167}{section*.208}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.18}{\ignorespaces BP计算过程示意图\relax }}{168}{figure.caption.209}}
\newlabel{BP0}{{9.18}{168}{BP计算过程示意图\relax }{figure.caption.209}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.17.1}Notes on CNNs}{168}{subsection.9.17.1}}
\@writefile{toc}{\contentsline {subsubsection}{CNN的目标函数，包含Weight Decay的形式}{168}{section*.210}}
\@writefile{toc}{\contentsline {subsubsection}{求解输出层的误差敏感项}{169}{section*.211}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.19}{\ignorespaces 目标函数对最后一层卷积层的输出，即最后一层Softmax的输入的求导\relax }}{169}{figure.caption.212}}
\newlabel{BP1}{{9.19}{169}{目标函数对最后一层卷积层的输出，即最后一层Softmax的输入的求导\relax }{figure.caption.212}{}}
\@writefile{toc}{\contentsline {subsubsection}{当卷积层的下一层是Pooling层时，求解卷积层的误差敏感项}{170}{section*.213}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.20}{\ignorespaces 则按照mean-pooling，首先得到的卷积层应该是4×4大小，其值分布为(等值复制).\relax }}{171}{figure.caption.214}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {输出的2*2Pooling结果}}}{171}{figure.caption.214}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {输入的4*4卷积层输出}}}{171}{figure.caption.214}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.21}{\ignorespaces 反向传播时的误差\relax }}{171}{figure.caption.215}}
\citation{Attention2014}
\@writefile{toc}{\contentsline {subsubsection}{当Pooling的下一层为卷积层时，求该Pooling层的误差敏感项}{172}{section*.216}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.17.2}Pooling层的反向传播}{172}{subsection.9.17.2}}
\@writefile{toc}{\contentsline {section}{\numberline {9.18}神经网络中的Attention机制}{172}{section.9.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.18.1}Recurrent Models of Visual Attention}{172}{subsection.9.18.1}}
\@writefile{toc}{\contentsline {subsubsection}{The Recurrent Attention Model - RAM }{173}{section*.217}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.22}{\ignorespaces Attention 模型示意图\relax }}{173}{figure.caption.218}}
\newlabel{Attention0}{{9.22}{173}{Attention 模型示意图\relax }{figure.caption.218}{}}
\@writefile{toc}{\contentsline {subsubsection}{总结}{174}{section*.219}}
\@writefile{toc}{\contentsline {section}{\numberline {9.19}小型网络}{174}{section.9.19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.19.1}理论分析}{174}{subsection.9.19.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.19.2}GCONV \& DWCONV}{174}{subsection.9.19.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.19.3}NiN及相关}{175}{subsection.9.19.3}}
\@writefile{toc}{\contentsline {section}{\numberline {9.20}Deep Reinforcement Learning}{175}{section.9.20}}
\@writefile{toc}{\contentsline {section}{\numberline {9.21}为什么Python中要继承object类}{175}{section.9.21}}
\@writefile{toc}{\contentsline {subsubsection}{Python 2.x story}{175}{section*.220}}
\@writefile{toc}{\contentsline {subsubsection}{Python 3.x story}{176}{section*.221}}
\@writefile{toc}{\contentsline {subsubsection}{Choose which one}{176}{section*.222}}
\@writefile{toc}{\contentsline {section}{\numberline {9.22}1*1卷积}{176}{section.9.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.23}{\ignorespaces 1*1 Convolutoin 的作用示意图\relax }}{177}{figure.caption.223}}
\newlabel{OneOneConv0}{{9.23}{177}{1*1 Convolutoin 的作用示意图\relax }{figure.caption.223}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.23}目标检测中完整流程}{177}{section.9.23}}
\@writefile{toc}{\contentsline {section}{\numberline {9.24}Batch Size的影响}{177}{section.9.24}}
\@writefile{toc}{\contentsline {section}{\numberline {9.25}非极大值抑制NMS}{177}{section.9.25}}
\@writefile{toc}{\contentsline {section}{\numberline {9.26}Bilinear filler初始化ConvTranspose层的权重}{178}{section.9.26}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9.2}Bilinear Filter Initializer实现代码-MXNet}{178}{lstlisting.9.2}}
\@writefile{toc}{\contentsline {section}{\numberline {9.27}卷积层输出的尺寸}{178}{section.9.27}}
\@writefile{toc}{\contentsline {section}{\numberline {9.28}机器学习面试博客总结2018.06.11}{179}{section.9.28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.28.1}大疆}{179}{subsection.9.28.1}}
\@writefile{toc}{\contentsline {subsubsection}{机器学习中的范数问题}{179}{section*.224}}
\@writefile{toc}{\contentsline {subsubsection}{类别中不平衡}{179}{section*.225}}
\@writefile{toc}{\contentsline {subsubsection}{Confusion Matrix}{179}{section*.226}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.24}{\ignorespaces Confusion Matrix示意图\relax }}{180}{figure.caption.227}}
\newlabel{ConfusionMatrix0}{{9.24}{180}{Confusion Matrix示意图\relax }{figure.caption.227}{}}
\@writefile{toc}{\contentsline {subsubsection}{ROC \& AUC}{180}{section*.228}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.28.2}机器学习面试总结}{180}{subsection.9.28.2}}
\@writefile{toc}{\contentsline {section}{\numberline {9.29}花书前两部分总结}{180}{section.9.29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.29.1}第三章}{180}{subsection.9.29.1}}
\@writefile{toc}{\contentsline {subsubsection}{概率论的知识}{180}{section*.229}}
\@writefile{toc}{\contentsline {subsubsection}{信息论}{180}{section*.230}}
\@writefile{toc}{\contentsline {subsubsection}{结构化概率模型}{181}{section*.231}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.29.2}第四章}{181}{subsection.9.29.2}}
\@writefile{toc}{\contentsline {subsubsection}{上溢和下溢}{181}{section*.232}}
\@writefile{toc}{\contentsline {subsubsection}{病态条件}{182}{section*.233}}
\@writefile{toc}{\contentsline {subsubsection}{基于梯度的优化方法}{182}{section*.234}}
\@writefile{toc}{\contentsline {subsubsection}{梯度之上}{182}{section*.235}}
\@writefile{toc}{\contentsline {subsubsection}{约束优化}{183}{section*.236}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.29.3}第五章}{183}{subsection.9.29.3}}
\@writefile{toc}{\contentsline {subsubsection}{设计矩阵}{183}{section*.237}}
\@writefile{toc}{\contentsline {subsubsection}{容量、过拟合和欠拟合}{183}{section*.238}}
\@writefile{toc}{\contentsline {subsubsection}{估计、偏差和方差}{184}{section*.239}}
\@writefile{toc}{\contentsline {subsubsection}{最大似然估计}{184}{section*.240}}
\@writefile{toc}{\contentsline {subsubsection}{贝叶斯估计}{185}{section*.241}}
\@writefile{toc}{\contentsline {subsubsection}{随机梯度下降}{185}{section*.242}}
\@writefile{toc}{\contentsline {subsubsection}{促使深度学习发展的挑战}{186}{section*.243}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.29.4}第六章}{186}{subsection.9.29.4}}
\@writefile{toc}{\contentsline {subsubsection}{基于梯度的学习}{186}{section*.244}}
\@writefile{toc}{\contentsline {subsubsection}{隐藏单元}{188}{section*.245}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.25}{\ignorespaces 激活函数对比\relax }}{191}{figure.caption.246}}
\newlabel{ActivationFunctions0}{{9.25}{191}{激活函数对比\relax }{figure.caption.246}{}}
\@writefile{toc}{\contentsline {subsubsection}{架构设计}{191}{section*.247}}
\@writefile{toc}{\contentsline {subsubsection}{反向传播}{191}{section*.248}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.29.5}第七章}{192}{subsection.9.29.5}}
\@writefile{toc}{\contentsline {subsubsection}{参数范数惩罚}{192}{section*.249}}
\@writefile{toc}{\contentsline {subsubsection}{数据集增强}{192}{section*.250}}
\@writefile{toc}{\contentsline {subsubsection}{噪声鲁棒性}{192}{section*.251}}
\@writefile{toc}{\contentsline {subsubsection}{半监督学习}{193}{section*.252}}
\@writefile{toc}{\contentsline {subsubsection}{多任务学习}{193}{section*.253}}
\@writefile{toc}{\contentsline {subsubsection}{提前终止}{193}{section*.254}}
\@writefile{toc}{\contentsline {subsubsection}{Bagging等集成方法}{193}{section*.255}}
\@writefile{toc}{\contentsline {subsubsection}{Dropout}{193}{section*.256}}
\@writefile{toc}{\contentsline {subsubsection}{对抗训练}{193}{section*.257}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.29.6}第八章}{193}{subsection.9.29.6}}
\@writefile{toc}{\contentsline {subsubsection}{神经网络优化中的挑战}{193}{section*.258}}
\@writefile{toc}{\contentsline {subsubsection}{基本算法}{194}{section*.259}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces SGD\relax }}{194}{algorithm.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces 使用动量的SGD\relax }}{195}{algorithm.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces 使用Nesterov动量的SGD\relax }}{195}{algorithm.3}}
\@writefile{toc}{\contentsline {subsubsection}{参数初始化策略}{196}{section*.260}}
\@writefile{toc}{\contentsline {subsubsection}{自适应学习率算法}{196}{section*.261}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces AdaGrad算法\relax }}{196}{algorithm.4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces RMSProp算法\relax }}{197}{algorithm.5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Adam算法\relax }}{198}{algorithm.6}}
\@writefile{toc}{\contentsline {subsubsection}{选择正确的优化算法}{198}{section*.262}}
\@writefile{toc}{\contentsline {subsubsection}{优化策略和元算法}{198}{section*.263}}
\@writefile{toc}{\contentsline {section}{\numberline {9.30}梯度消失-梯度爆炸 专题}{198}{section.9.30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.30.1}自圆其说的解释}{199}{subsection.9.30.1}}
\@writefile{toc}{\contentsline {section}{\numberline {9.31}ROI Pooling}{199}{section.9.31}}
\@writefile{toc}{\contentsline {section}{\numberline {9.32}深度学习面试100题}{199}{section.9.32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.1}Tensorflow计算图}{199}{subsection.9.32.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.2}DL调参}{200}{subsection.9.32.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.3}为什么CNN在CV、NLP、Sppech、AlphaGo里面都有应用}{200}{subsection.9.32.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.4}为什么要引入非线性激励函数}{201}{subsection.9.32.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.5}为什么ReLU要好于tanh和sigmoid function}{201}{subsection.9.32.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.6}为啥LSTM模型中既存在sigmoid又存在tanh两种激活函数}{201}{subsection.9.32.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.7}如何解决RNN梯度爆炸和弥散问题}{201}{subsection.9.32.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.8}什么样的数据集不适合深度学习}{202}{subsection.9.32.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.9}如何解决梯度消失和梯度膨胀}{202}{subsection.9.32.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.10}激活函数的真正意义}{202}{subsection.9.32.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.32.11}梯度下降训练神经网络容易收敛到局部最优，为什么还应用广泛}{203}{subsection.9.32.11}}
\@writefile{toc}{\contentsline {section}{\numberline {9.33}数据的归一化}{203}{section.9.33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.33.1}为什么需要归一化}{203}{subsection.9.33.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.33.2}归一化的方法}{203}{subsection.9.33.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.33.3}小结}{204}{subsection.9.33.3}}
\@writefile{toc}{\contentsline {section}{\numberline {9.34}待续}{204}{section.9.34}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Image Processing}{205}{chapter.10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Feature Extraction}{205}{section.10.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.1}SIFT}{205}{subsection.10.1.1}}
\citation{Felzenszwalb2004}
\citation{Felzenszwalb2004}
\citation{Felzenszwalb2004}
\citation{Uijlings2013}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Feature Extraction}{207}{chapter.11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Selective Search}{207}{section.11.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.1}Efficient Graph-Based Image Segmentation}{207}{subsection.11.1.1}}
\citation{Felzenszwalb2004}
\citation{he2014spatial}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.2}Selective Search}{208}{subsection.11.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Region CNN}{208}{section.11.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}概述}{208}{subsection.11.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces RCNN整体思想 \relax }}{208}{figure.caption.264}}
\newlabel{RCNN0}{{11.1}{208}{RCNN整体思想 \relax }{figure.caption.264}{}}
\@writefile{toc}{\contentsline {subsubsection}{Boundingbox 回归}{208}{section*.265}}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}SPP Net}{208}{section.11.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.1}背景与相关工作}{208}{subsection.11.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces Pyramid Pooling在网络结构中的示意图，与传统CNN结构的比较\relax }}{209}{figure.caption.266}}
\newlabel{SPPNet0}{{11.2}{209}{Pyramid Pooling在网络结构中的示意图，与传统CNN结构的比较\relax }{figure.caption.266}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.2}网络结构}{209}{subsection.11.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Fisher Kernel}{209}{section*.267}}
\@writefile{toc}{\contentsline {subsubsection}{Convolutional Layers and Feature Maps}{210}{section*.268}}
\@writefile{toc}{\contentsline {subsubsection}{The Spatial Pyramid Pooling Layer}{210}{section*.269}}
\@writefile{toc}{\contentsline {subsubsection}{Training}{210}{section*.271}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.3}Object Detection Experiments}{210}{subsection.11.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces Pyramid Pooling的计算过程示意图\relax }}{211}{figure.caption.270}}
\newlabel{SPPNet1}{{11.3}{211}{Pyramid Pooling的计算过程示意图\relax }{figure.caption.270}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.4}Conclusion}{211}{subsection.11.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Fast RCNN}{212}{section.11.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.1}ROI-Pooling层的实现-知乎}{212}{subsection.11.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{ROI Pooling层}{212}{section*.272}}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Faster RCNN}{213}{section.11.5}}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}R FCN}{213}{section.11.6}}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Mask RCNN}{213}{section.11.7}}
\@writefile{toc}{\contentsline {section}{\numberline {11.8}YOLO}{213}{section.11.8}}
\@writefile{toc}{\contentsline {section}{\numberline {11.9}YOLO v2}{213}{section.11.9}}
\@writefile{toc}{\contentsline {section}{\numberline {11.10}YOLO v3}{213}{section.11.10}}
\@writefile{toc}{\contentsline {section}{\numberline {11.11}SSD}{213}{section.11.11}}
\@writefile{toc}{\contentsline {section}{\numberline {11.12}DSSD}{213}{section.11.12}}
\@writefile{toc}{\contentsline {section}{\numberline {11.13}Retina Net (Focal Loss)}{213}{section.11.13}}
\@writefile{toc}{\contentsline {section}{\numberline {11.14}Feature Pyramid Network}{213}{section.11.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.14.1}Nearest Neighbor Interpolation}{213}{subsection.11.14.1}}
\@writefile{toc}{\contentsline {section}{\numberline {11.15}ResNet}{213}{section.11.15}}
\citation{*}
\bibdata{reference}
\bibcite{asano2009performance}{1}
\bibcite{chen18iterative}{2}
\bibcite{eitel2015multimodal}{3}
\bibcite{Felzenszwalb2004}{4}
\bibcite{Felzenszwalb2004Efficient}{5}
\bibcite{Goodfellow2014GAN}{6}
\bibcite{gupta2014learning}{7}
\bibcite{maskrcnn2017he}{8}
\bibcite{he2014spatial}{9}
\bibcite{senet2017hu}{10}
\bibcite{hu2017learning}{11}
\bibcite{Hui2018LiteFlowNet}{12}
\bibcite{iglovikov2018ternausnetv2}{13}
\bibcite{li2017fast}{14}
\bibcite{li2013image}{15}
\bibcite{li2016fully}{16}
\bibcite{liu2018path}{17}
\bibcite{Fcn2014}{18}
\bibcite{marvin2018crf}{19}
\bibcite{SemanticFusion2016}{20}
\bibcite{Mehta2018OD200}{21}
\bibcite{Attention2014}{22}
\bibcite{Pham2016Geometrically}{23}
\bibcite{qi20173d}{24}
\bibcite{ren2017end}{25}
\bibcite{U-Net2015}{26}
\bibcite{runz2017co}{27}
\bibcite{SemanticVisualLocalization2017}{28}
\bibcite{scona2018staticfusion}{29}
\bibcite{Silvia2018Recurrent}{30}
\bibcite{Meaningful2016}{31}
\bibcite{teichmann2018convolutional}{32}
\bibcite{toet2016multiscale}{33}
\bibcite{Uijlings2013}{34}
\bibcite{ReSeg2015}{35}
\bibcite{WangWang2018DeLS}{36}
\bibcite{Wang2018DenseSLAMNet}{37}
\bibcite{Xiang2017DARNN}{38}
\bibcite{Xu2018PADNet}{39}
\bibcite{YuKoltun2016}{40}
