\BOOKMARK [0][-]{chapter.1}{Image\040processing\040based\040on\040CUDA}{}% 1
\BOOKMARK [1][-]{section.1.1}{Novel\040multi-scale\040retinex\040with\040color\040restoration\040on\040graphics\040processing\040unit}{chapter.1}% 2
\BOOKMARK [2][-]{subsection.1.1.1}{Abstract}{section.1.1}% 3
\BOOKMARK [2][-]{subsection.1.1.2}{Content}{section.1.1}% 4
\BOOKMARK [2][-]{subsection.1.1.3}{Parallel\040optimization\040strage}{section.1.1}% 5
\BOOKMARK [2][-]{subsection.1.1.4}{Conclusion}{section.1.1}% 6
\BOOKMARK [1][-]{section.1.2}{Image\040Convolution}{chapter.1}% 7
\BOOKMARK [2][-]{subsection.1.2.1}{Naïve Implementation}{section.1.2}% 8
\BOOKMARK [2][-]{subsection.1.2.2}{Naïve Shared Memory Implementation}{section.1.2}% 9
\BOOKMARK [2][-]{subsection.1.2.3}{Separable\040Gaussian\040Filtering}{section.1.2}% 10
\BOOKMARK [2][-]{subsection.1.2.4}{Optimizing\040for\040memory\040coalescence}{section.1.2}% 11
\BOOKMARK [1][-]{section.1.3}{CUDA\040C\040Best\040Practice\040Guide}{chapter.1}% 12
\BOOKMARK [2][-]{subsection.1.3.1}{Performance\040Metrics}{section.1.3}% 13
\BOOKMARK [1][-]{section.1.4}{Npp\040Library\040Image\040Filters}{chapter.1}% 14
\BOOKMARK [2][-]{subsection.1.4.1}{Image\040Data}{section.1.4}% 15
\BOOKMARK [1][-]{section.1.5}{PTX\040ISA\0406.0}{chapter.1}% 16
\BOOKMARK [2][-]{subsection.1.5.1}{PTX\040Machine\040Model}{section.1.5}% 17
\BOOKMARK [0][-]{chapter.2}{FPGAs}{}% 18
\BOOKMARK [1][-]{section.2.1}{Performance\040Comparison\040of\040FPGA,\040GPU\040and\040CPU\040in\040Image\040Processing\0402009}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.1.1}{Abstract}{section.2.1}% 20
\BOOKMARK [2][-]{subsection.2.1.2}{Content}{section.2.1}% 21
\BOOKMARK [2][-]{subsection.2.1.3}{Results}{section.2.1}% 22
\BOOKMARK [2][-]{subsection.2.1.4}{Conclusion}{section.2.1}% 23
\BOOKMARK [1][-]{section.2.2}{Fast\040FPGA\040Prototyping\040for\040real-time\040image\040processing\040with\040very\040high-level\040synthesis\0402017}{chapter.2}% 24
\BOOKMARK [2][-]{subsection.2.2.1}{Abstract}{section.2.2}% 25
\BOOKMARK [2][-]{subsection.2.2.2}{Content}{section.2.2}% 26
\BOOKMARK [0][-]{chapter.3}{Image\040Fusion}{}% 27
\BOOKMARK [1][-]{section.3.1}{Guided\040Image\040Filter\0402013}{chapter.3}% 28
\BOOKMARK [2][-]{subsection.3.1.1}{Abstract}{section.3.1}% 29
\BOOKMARK [2][-]{subsection.3.1.2}{Content}{section.3.1}% 30
\BOOKMARK [2][-]{subsection.3.1.3}{Conclusion}{section.3.1}% 31
\BOOKMARK [1][-]{section.3.2}{Multiscale\040Image\040Fusion\040Through\040Guided\040Filtering}{chapter.3}% 32
\BOOKMARK [2][-]{subsection.3.2.1}{Abstract}{section.3.2}% 33
\BOOKMARK [2][-]{subsection.3.2.2}{Contents}{section.3.2}% 34
\BOOKMARK [2][-]{subsection.3.2.3}{Conclusion}{section.3.2}% 35
\BOOKMARK [1][-]{section.3.3}{Image\040Fusion\040With\040Guided\040Filtering}{chapter.3}% 36
\BOOKMARK [2][-]{subsection.3.3.1}{Abstract}{section.3.3}% 37
\BOOKMARK [2][-]{subsection.3.3.2}{Contents}{section.3.3}% 38
\BOOKMARK [2][-]{subsection.3.3.3}{Fusion\040Frame}{section.3.3}% 39
\BOOKMARK [2][-]{subsection.3.3.4}{Conclusion}{section.3.3}% 40
\BOOKMARK [0][-]{chapter.4}{Saliency\040Detection}{}% 41
\BOOKMARK [1][-]{section.4.1}{Frequency-tuned\040Salient\040Region\040Detection}{chapter.4}% 42
\BOOKMARK [2][-]{subsection.4.1.1}{Abstract}{section.4.1}% 43
\BOOKMARK [2][-]{subsection.4.1.2}{Contents}{section.4.1}% 44
\BOOKMARK [2][-]{subsection.4.1.3}{Conclusion}{section.4.1}% 45
\BOOKMARK [0][-]{chapter.5}{Semantic\040SLAM}{}% 46
\BOOKMARK [1][-]{section.5.1}{DeLS-3D:\040Deep\040Localization\040and\040Segmentation\040with\040a\0402D\040Semantic\040MapWangWang2018DeLS}{chapter.5}% 47
\BOOKMARK [2][-]{subsection.5.1.1}{Abstract}{section.5.1}% 48
\BOOKMARK [2][-]{subsection.5.1.2}{Introduction}{section.5.1}% 49
\BOOKMARK [2][-]{subsection.5.1.3}{Framework}{section.5.1}% 50
\BOOKMARK [2][-]{subsection.5.1.4}{Related\040Work}{section.5.1}% 51
\BOOKMARK [2][-]{subsection.5.1.5}{Dataset}{section.5.1}% 52
\BOOKMARK [2][-]{subsection.5.1.6}{Localizing\040camera\040and\040Scene\040Parsing}{section.5.1}% 53
\BOOKMARK [2][-]{subsection.5.1.7}{Experiment}{section.5.1}% 54
\BOOKMARK [2][-]{subsection.5.1.8}{Conclusion}{section.5.1}% 55
\BOOKMARK [1][-]{section.5.2}{PAD-Net:\040Multi-Task\040Guided\040Prediction-and-Distillation\040Network\040for\040Simultaneous\040Depth\040and\040Scene\040Parsing\040Xu2018PADNet}{chapter.5}% 56
\BOOKMARK [2][-]{subsection.5.2.1}{Abstract}{section.5.2}% 57
\BOOKMARK [2][-]{subsection.5.2.2}{Analysis}{section.5.2}% 58
\BOOKMARK [1][-]{section.5.3}{RNN\040for\040Learning\040Dense\040Depth\040and\040Ego-Motion\040from\040Video}{chapter.5}% 59
\BOOKMARK [2][-]{subsection.5.3.1}{Abstract}{section.5.3}% 60
\BOOKMARK [2][-]{subsection.5.3.2}{Introduction\040&\040Related\040Works}{section.5.3}% 61
\BOOKMARK [2][-]{subsection.5.3.3}{Network\040Architecture}{section.5.3}% 62
\BOOKMARK [2][-]{subsection.5.3.4}{Training}{section.5.3}% 63
\BOOKMARK [2][-]{subsection.5.3.5}{Experiments}{section.5.3}% 64
\BOOKMARK [2][-]{subsection.5.3.6}{Ablation\040Studies}{section.5.3}% 65
\BOOKMARK [1][-]{section.5.4}{DA-RNN}{chapter.5}% 66
\BOOKMARK [2][-]{subsection.5.4.1}{Related\040Works}{section.5.4}% 67
\BOOKMARK [2][-]{subsection.5.4.2}{Methods}{section.5.4}% 68
\BOOKMARK [2][-]{subsection.5.4.3}{Experiments}{section.5.4}% 69
\BOOKMARK [2][-]{subsection.5.4.4}{Conclusion}{section.5.4}% 70
\BOOKMARK [1][-]{section.5.5}{SemanticFusion:\040Dense\0403D\040Semantic\040Mapping\040with\040CNNs}{chapter.5}% 71
\BOOKMARK [2][-]{subsection.5.5.1}{Introduction\040&\040Related\040Works}{section.5.5}% 72
\BOOKMARK [2][-]{subsection.5.5.2}{Method}{section.5.5}% 73
\BOOKMARK [2][-]{subsection.5.5.3}{Experiments}{section.5.5}% 74
\BOOKMARK [2][-]{subsection.5.5.4}{总结}{section.5.5}% 75
\BOOKMARK [1][-]{section.5.6}{Meaningful\040Maps\040with\040Object-Oriented\040Semantic\040Mapping}{chapter.5}% 76
\BOOKMARK [2][-]{subsection.5.6.1}{Introduction\040&\040Related\040Works}{section.5.6}% 77
\BOOKMARK [2][-]{subsection.5.6.2}{Object\040Oriented\040Semantic\040Mapping}{section.5.6}% 78
\BOOKMARK [2][-]{subsection.5.6.3}{总结}{section.5.6}% 79
\BOOKMARK [1][-]{section.5.7}{LiteFlowNet}{chapter.5}% 80
\BOOKMARK [2][-]{subsection.5.7.1}{背景知识}{section.5.7}% 81
\BOOKMARK [2][-]{subsection.5.7.2}{Related\040Works}{section.5.7}% 82
\BOOKMARK [2][-]{subsection.5.7.3}{LiteFlowNet}{section.5.7}% 83
\BOOKMARK [2][-]{subsection.5.7.4}{Ablation\040Study}{section.5.7}% 84
\BOOKMARK [2][-]{subsection.5.7.5}{Regularization}{section.5.7}% 85
\BOOKMARK [2][-]{subsection.5.7.6}{Conclusion}{section.5.7}% 86
\BOOKMARK [1][-]{section.5.8}{小结}{chapter.5}% 87
\BOOKMARK [1][-]{section.5.9}{ExFuse:\040Enhancing\040Feature\040Fusion\040for\040Semantic\040Segmentation}{chapter.5}% 88
\BOOKMARK [2][-]{subsection.5.9.1}{要解决的问题}{section.5.9}% 89
\BOOKMARK [2][-]{subsection.5.9.2}{Method}{section.5.9}% 90
\BOOKMARK [1][-]{section.5.10}{Multi-View\040Deep\040Learning\040for\040Consistent\040Semantic\040Mapping\040with\040RGB-D\040Cameras}{chapter.5}% 91
\BOOKMARK [2][-]{subsection.5.10.1}{Introduction\040&\040Related\040Works}{section.5.10}% 92
\BOOKMARK [2][-]{subsection.5.10.2}{CNN\040Architecture\040For\040Semantic\040Segmentation}{section.5.10}% 93
\BOOKMARK [2][-]{subsection.5.10.3}{Multi-View\040Consistent\040Learning\040and\040Prediction}{section.5.10}% 94
\BOOKMARK [2][-]{subsection.5.10.4}{Experiments}{section.5.10}% 95
\BOOKMARK [2][-]{subsection.5.10.5}{总结}{section.5.10}% 96
\BOOKMARK [1][-]{section.5.11}{MaskFusion}{chapter.5}% 97
\BOOKMARK [2][-]{subsection.5.11.1}{背景及相关工作}{section.5.11}% 98
\BOOKMARK [2][-]{subsection.5.11.2}{System\040Design}{section.5.11}% 99
\BOOKMARK [2][-]{subsection.5.11.3}{Evaluation}{section.5.11}% 100
\BOOKMARK [2][-]{subsection.5.11.4}{总结}{section.5.11}% 101
\BOOKMARK [1][-]{section.5.12}{小结 2}{chapter.5}% 102
\BOOKMARK [1][-]{section.5.13}{CNN-SLAM}{chapter.5}% 103
\BOOKMARK [1][-]{section.5.14}{图像语义分割之FCN和CRF}{chapter.5}% 104
\BOOKMARK [2][-]{subsection.5.14.1}{前端FCN}{section.5.14}% 105
\BOOKMARK [2][-]{subsection.5.14.2}{DeepLab}{section.5.14}% 106
\BOOKMARK [2][-]{subsection.5.14.3}{后端优化CRF/MRF}{section.5.14}% 107
\BOOKMARK [2][-]{subsection.5.14.4}{小结}{section.5.14}% 108
\BOOKMARK [1][-]{section.5.15}{Learning\040Deconvolution\040Network\040for\040Semantic}{chapter.5}% 109
\BOOKMARK [1][-]{section.5.16}{ReSeg\0402015}{chapter.5}% 110
\BOOKMARK [2][-]{subsection.5.16.1}{背景 & 相关工作}{section.5.16}% 111
\BOOKMARK [2][-]{subsection.5.16.2}{Model\040Description}{section.5.16}% 112
\BOOKMARK [2][-]{subsection.5.16.3}{实验结果}{section.5.16}% 113
\BOOKMARK [2][-]{subsection.5.16.4}{总结}{section.5.16}% 114
\BOOKMARK [1][-]{section.5.17}{U-Net}{chapter.5}% 115
\BOOKMARK [2][-]{subsection.5.17.1}{Network\040Architecture}{section.5.17}% 116
\BOOKMARK [2][-]{subsection.5.17.2}{Conclusion}{section.5.17}% 117
\BOOKMARK [2][-]{subsection.5.17.3}{补充}{section.5.17}% 118
\BOOKMARK [1][-]{section.5.18}{Semantic\040Visual\040Localization}{chapter.5}% 119
\BOOKMARK [2][-]{subsection.5.18.1}{背景 & 相关工作}{section.5.18}% 120
\BOOKMARK [2][-]{subsection.5.18.2}{Semantic\040Visual\040Localization}{section.5.18}% 121
\BOOKMARK [2][-]{subsection.5.18.3}{Experiments}{section.5.18}% 122
\BOOKMARK [2][-]{subsection.5.18.4}{Conclusions}{section.5.18}% 123
\BOOKMARK [1][-]{section.5.19}{小结3}{chapter.5}% 124
\BOOKMARK [1][-]{section.5.20}{StaticFusion}{chapter.5}% 125
\BOOKMARK [2][-]{subsection.5.20.1}{背景}{section.5.20}% 126
\BOOKMARK [2][-]{subsection.5.20.2}{动态场景下SLAM系统的相关工作}{section.5.20}% 127
\BOOKMARK [2][-]{subsection.5.20.3}{Framework和Notation}{section.5.20}% 128
\BOOKMARK [1][-]{section.5.21}{Convolutional\040CRFs\040for\040Semantic\040Segmentation}{chapter.5}% 129
\BOOKMARK [2][-]{subsection.5.21.1}{背景 & 相关工作}{section.5.21}% 130
\BOOKMARK [2][-]{subsection.5.21.2}{Fully\040Connected\040CRFs}{section.5.21}% 131
\BOOKMARK [2][-]{subsection.5.21.3}{Convolutional\040CRFs}{section.5.21}% 132
\BOOKMARK [2][-]{subsection.5.21.4}{总结}{section.5.21}% 133
\BOOKMARK [1][-]{section.5.22}{Co-Fusion}{chapter.5}% 134
\BOOKMARK [1][-]{section.5.23}{Squeeze-and-Excitation\040Networks}{chapter.5}% 135
\BOOKMARK [1][-]{section.5.24}{Deep\040Multi-scale\040Architectures\040For\040Monocular\040Depth\040Estimation}{chapter.5}% 136
\BOOKMARK [2][-]{subsection.5.24.1}{背景与相关工作}{section.5.24}% 137
\BOOKMARK [1][-]{section.5.25}{Depth\040Map\040Prediction\040from\040a\040single\040image\040usign\040a\040multi-Scale\040Deep\040Network}{chapter.5}% 138
\BOOKMARK [1][-]{section.5.26}{Mask\040R-CNN}{chapter.5}% 139
\BOOKMARK [2][-]{subsection.5.26.1}{研究现状与相关背景}{section.5.26}% 140
\BOOKMARK [2][-]{subsection.5.26.2}{Mask\040RCNN}{section.5.26}% 141
\BOOKMARK [2][-]{subsection.5.26.3}{实验}{section.5.26}% 142
\BOOKMARK [2][-]{subsection.5.26.4}{总结}{section.5.26}% 143
\BOOKMARK [1][-]{section.5.27}{Learning\040to\040segment\040every\040thing}{chapter.5}% 144
\BOOKMARK [1][-]{section.5.28}{Path\040aggregation\040network\040for\040instance\040segmentation}{chapter.5}% 145
\BOOKMARK [1][-]{section.5.29}{End-to-End\040Instance\040Segmentation\040with\040Recurrent\040Attention}{chapter.5}% 146
\BOOKMARK [1][-]{section.5.30}{Fully\040Convolutional\040Instance-aware\040Semantic\040Segmentation}{chapter.5}% 147
\BOOKMARK [2][-]{subsection.5.30.1}{背景与相关现状}{section.5.30}% 148
\BOOKMARK [2][-]{subsection.5.30.2}{Our\040Approach}{section.5.30}% 149
\BOOKMARK [1][-]{section.5.31}{TernausNetV2:\040Fully\040Convolutional\040Network\040for\040Instance\040Segmentation}{chapter.5}% 150
\BOOKMARK [2][-]{subsection.5.31.1}{背景及相关工作}{section.5.31}% 151
\BOOKMARK [2][-]{subsection.5.31.2}{Model}{section.5.31}% 152
\BOOKMARK [2][-]{subsection.5.31.3}{Training}{section.5.31}% 153
\BOOKMARK [2][-]{subsection.5.31.4}{常用数据集}{section.5.31}% 154
\BOOKMARK [2][-]{subsection.5.31.5}{KITTI}{section.5.31}% 155
\BOOKMARK [2][-]{subsection.5.31.6}{官网资源介绍}{section.5.31}% 156
\BOOKMARK [2][-]{subsection.5.31.7}{详述}{section.5.31}% 157
\BOOKMARK [2][-]{subsection.5.31.8}{Cityscape}{section.5.31}% 158
\BOOKMARK [2][-]{subsection.5.31.9}{TUM}{section.5.31}% 159
\BOOKMARK [1][-]{section.5.32}{实例分割-图像分割2018.06.11博客总结}{chapter.5}% 160
\BOOKMARK [2][-]{subsection.5.32.1}{Mask R-CNN狙击目标实例分割}{section.5.32}% 161
\BOOKMARK [1][-]{section.5.33}{无需Proposal的实例分割论文}{chapter.5}% 162
\BOOKMARK [1][-]{section.5.34}{Learning\040Rich\040Features\040from\040RGB-D\040Images\040for\040Object\040Detection\040and\040Segmentation}{chapter.5}% 163
\BOOKMARK [1][-]{section.5.35}{Multimodal\040Deep\040Learning\040for\040Robust\040RGB-D\040Object\040Recognition}{chapter.5}% 164
\BOOKMARK [1][-]{section.5.36}{3D\040Graph\040Neural\040Networks\040for\040RGBD\040Semantic\040Segmentation}{chapter.5}% 165
\BOOKMARK [1][-]{section.5.37}{RefineNet}{chapter.5}% 166
\BOOKMARK [2][-]{subsection.5.37.1}{引言中的重要几点}{section.5.37}% 167
\BOOKMARK [2][-]{subsection.5.37.2}{算法思想}{section.5.37}% 168
\BOOKMARK [2][-]{subsection.5.37.3}{实验部分}{section.5.37}% 169
\BOOKMARK [2][-]{subsection.5.37.4}{小结}{section.5.37}% 170
\BOOKMARK [1][-]{section.5.38}{RedNet:\040Residual\040Encoder-Decoder\040Network\040for\040indoor\040RGB-D\040Semantic\040Segmentation}{chapter.5}% 171
\BOOKMARK [1][-]{section.5.39}{RDFNet:\040RGB-D\040Multi-level\040Residual\040Feature\040fusion\040for\040Indoor\040Sematnic\040Segmentation}{chapter.5}% 172
\BOOKMARK [1][-]{section.5.40}{Progressively\040Complementarity-aware\040Fusion\040Network\040for\040RGB-D\040Salient\040Object\040Detection}{chapter.5}% 173
\BOOKMARK [1][-]{section.5.41}{Semantic-Guided\040Multi-level\040RGB-D\040Feature\040Fusion\040for\040Indoor\040Semantic\040segmentation}{chapter.5}% 174
\BOOKMARK [1][-]{section.5.42}{Learning\040Common\040and\040Specific\040Features\040for\040RGB-D\040Semantic\040Segmentation\040with\040Deconvolutional\040Networks}{chapter.5}% 175
\BOOKMARK [0][-]{chapter.6}{Open\040Set\040Recognition}{}% 176
\BOOKMARK [1][-]{section.6.1}{GAN}{chapter.6}% 177
\BOOKMARK [2][-]{subsection.6.1.1}{GAN 原理笔记}{section.6.1}% 178
\BOOKMARK [1][-]{section.6.2}{从头开始GAN}{chapter.6}% 179
\BOOKMARK [2][-]{subsection.6.2.1}{定义}{section.6.2}% 180
\BOOKMARK [2][-]{subsection.6.2.2}{DCGAN： Deep Convolution GAN}{section.6.2}% 181
\BOOKMARK [2][-]{subsection.6.2.3}{CGAN:\040Conditional\040Generative\040Adversarial\040Nets}{section.6.2}% 182
\BOOKMARK [2][-]{subsection.6.2.4}{InfoGAN}{section.6.2}% 183
\BOOKMARK [1][-]{section.6.3}{Generative\040Adversarial\040Nets}{chapter.6}% 184
\BOOKMARK [1][-]{section.6.4}{Towards\040Open\040Set\040Deep\040Networks}{chapter.6}% 185
\BOOKMARK [2][-]{subsection.6.4.1}{Introduction\040&\040Related\040Works}{section.6.4}% 186
\BOOKMARK [1][-]{section.6.5}{Probability\040Models\040for\040Open\040Set\040Recognition}{chapter.6}% 187
\BOOKMARK [2][-]{subsection.6.5.1}{背景及相关工作}{section.6.5}% 188
\BOOKMARK [1][-]{section.6.6}{Meta\040Recognition}{chapter.6}% 189
\BOOKMARK [2][-]{subsection.6.6.1}{该死的Fisher-Tippet Theorem}{section.6.6}% 190
\BOOKMARK [2][-]{subsection.6.6.2}{Weibull\040Distribution}{section.6.6}% 191
\BOOKMARK [0][-]{chapter.7}{MXNet}{}% 192
\BOOKMARK [1][-]{section.7.1}{MXNet\040System\040Overview}{chapter.7}% 193
\BOOKMARK [2][-]{subsection.7.1.1}{MXNet\040System\040Architecture}{section.7.1}% 194
\BOOKMARK [2][-]{subsection.7.1.2}{MXNet\040System\040Components}{section.7.1}% 195
\BOOKMARK [1][-]{section.7.2}{Optimizing\040Memory\040Consumption\040in\040DL}{chapter.7}% 196
\BOOKMARK [2][-]{subsection.7.2.1}{Computation\040Graph}{section.7.2}% 197
\BOOKMARK [2][-]{subsection.7.2.2}{What\040Can\040be\040Optimized?}{section.7.2}% 198
\BOOKMARK [2][-]{subsection.7.2.3}{Memory\040Allocation\040Algorithm}{section.7.2}% 199
\BOOKMARK [2][-]{subsection.7.2.4}{Static\040vs.\040Dynamic\040Allocation}{section.7.2}% 200
\BOOKMARK [2][-]{subsection.7.2.5}{Memory\040Allocation\040for\040Parallel\040Operations}{section.7.2}% 201
\BOOKMARK [2][-]{subsection.7.2.6}{How\040Much\040Can\040we\040Save\040?}{section.7.2}% 202
\BOOKMARK [2][-]{subsection.7.2.7}{References}{section.7.2}% 203
\BOOKMARK [1][-]{section.7.3}{Deep\040Learning\040Programming\040Style}{chapter.7}% 204
\BOOKMARK [2][-]{subsection.7.3.1}{Symbolic\040vs.\040Imperative\040Program}{section.7.3}% 205
\BOOKMARK [2][-]{subsection.7.3.2}{Imperative\040Programs\040Tend\040to\040be\040More\040Flexible}{section.7.3}% 206
\BOOKMARK [2][-]{subsection.7.3.3}{Symbolic\040Programs\040Tend\040to\040be\040More\040Efficient}{section.7.3}% 207
\BOOKMARK [2][-]{subsection.7.3.4}{Case\040Study:\040Backprop\040and\040AutoDiff}{section.7.3}% 208
\BOOKMARK [2][-]{subsection.7.3.5}{Model\040Checkpoint}{section.7.3}% 209
\BOOKMARK [2][-]{subsection.7.3.6}{Big\040vs.\040Small\040Operations}{section.7.3}% 210
\BOOKMARK [2][-]{subsection.7.3.7}{Mix\040The\040Approaches}{section.7.3}% 211
\BOOKMARK [1][-]{section.7.4}{Dependency\040Engine\040for\040Deep\040Learning}{chapter.7}% 212
\BOOKMARK [2][-]{subsection.7.4.1}{Problems\040in\040Dependency\040Scheduling}{section.7.4}% 213
\BOOKMARK [2][-]{subsection.7.4.2}{Implementing\040the\040Generic\040Dependency\040Engine}{section.7.4}% 214
\BOOKMARK [2][-]{subsection.7.4.3}{Discussion}{section.7.4}% 215
\BOOKMARK [1][-]{section.7.5}{Designing\040Efficient\040Data\040Loaders\040for\040DL}{chapter.7}% 216
\BOOKMARK [2][-]{subsection.7.5.1}{Design\040Insight}{section.7.5}% 217
\BOOKMARK [2][-]{subsection.7.5.2}{Data\040Format}{section.7.5}% 218
\BOOKMARK [2][-]{subsection.7.5.3}{Data\040Loading\040and\040Preprocessing}{section.7.5}% 219
\BOOKMARK [2][-]{subsection.7.5.4}{MXNet\040IO\040Python\040Interface}{section.7.5}% 220
\BOOKMARK [1][-]{section.7.6}{Except\040Handling\040in\040MXNet}{chapter.7}% 221
\BOOKMARK [1][-]{section.7.7}{MXNet-Gluon创建模型}{chapter.7}% 222
\BOOKMARK [2][-]{subsection.7.7.1}{模型构造}{section.7.7}% 223
\BOOKMARK [2][-]{subsection.7.7.2}{自定义层}{section.7.7}% 224
\BOOKMARK [2][-]{subsection.7.7.3}{实际例子}{section.7.7}% 225
\BOOKMARK [1][-]{section.7.8}{MXNet中的Deconvolution}{chapter.7}% 226
\BOOKMARK [1][-]{section.7.9}{MXNet读取训练数据}{chapter.7}% 227
\BOOKMARK [2][-]{subsection.7.9.1}{使用mx.io读取数据}{section.7.9}% 228
\BOOKMARK [2][-]{subsection.7.9.2}{常用的系统提供的接口函数}{section.7.9}% 229
\BOOKMARK [2][-]{subsection.7.9.3}{使用mx.image读取数据}{section.7.9}% 230
\BOOKMARK [2][-]{subsection.7.9.4}{使用Gluon接口读取数据}{section.7.9}% 231
\BOOKMARK [1][-]{section.7.10}{Gluon中的数据结构}{chapter.7}% 232
\BOOKMARK [1][-]{section.7.11}{MXNet中的Confusing参数}{chapter.7}% 233
\BOOKMARK [2][-]{subsection.7.11.1}{mx.symbol.reshape}{section.7.11}% 234
\BOOKMARK [2][-]{subsection.7.11.2}{mx.symbol.transpose}{section.7.11}% 235
\BOOKMARK [1][-]{section.7.12}{UpSample\040In\040MXNet}{chapter.7}% 236
\BOOKMARK [2][-]{subsection.7.12.1}{总结}{section.7.12}% 237
\BOOKMARK [1][-]{section.7.13}{MXNet中设置层的学习率}{chapter.7}% 238
\BOOKMARK [1][-]{section.7.14}{SoftmaxCrossEntropyLoss释疑}{chapter.7}% 239
\BOOKMARK [1][-]{section.7.15}{MXNet中的3D CNN}{chapter.7}% 240
\BOOKMARK [2][-]{subsection.7.15.1}{应该怎么理解3D CNN}{section.7.15}% 241
\BOOKMARK [1][-]{section.7.16}{向MXNet添加新的操作}{chapter.7}% 242
\BOOKMARK [2][-]{subsection.7.16.1}{添加新的Operator}{section.7.16}% 243
\BOOKMARK [2][-]{subsection.7.16.2}{添加新的Layer}{section.7.16}% 244
\BOOKMARK [1][-]{section.7.17}{关于MXNet里面的register修饰符}{chapter.7}% 245
\BOOKMARK [2][-]{subsection.7.17.1}{调用顺序-CSDN博客}{section.7.17}% 246
\BOOKMARK [2][-]{subsection.7.17.2}{Python中的装饰器之register}{section.7.17}% 247
\BOOKMARK [0][-]{chapter.8}{GPU\040Optimization\040in\040DL}{}% 248
\BOOKMARK [1][-]{section.8.1}{In-Place\040Activated\040BatchNorm\040for\040Memory-Optimized\040Training\040of\040DNNs}{chapter.8}% 249
\BOOKMARK [1][-]{section.8.2}{Training\040deep\040nets\040with\040sublinear\040memory\040cost}{chapter.8}% 250
\BOOKMARK [1][-]{section.8.3}{Memory-efficient\040backpropagation\040through\040time}{chapter.8}% 251
\BOOKMARK [1][-]{section.8.4}{The\040Reversible\040Residual\040Network:\040Backpropagation\040Without\040Storing\040Activations}{chapter.8}% 252
\BOOKMARK [1][-]{section.8.5}{}{chapter.8}% 253
\BOOKMARK [0][-]{chapter.9}{Tips\040in\040DL}{}% 254
\BOOKMARK [1][-]{section.9.1}{Enlarge\040the\040FOV}{chapter.9}% 255
\BOOKMARK [1][-]{section.9.2}{Upsampling}{chapter.9}% 256
\BOOKMARK [1][-]{section.9.3}{Multiscale\040Ability}{chapter.9}% 257
\BOOKMARK [1][-]{section.9.4}{Dilated\040Convolution}{chapter.9}% 258
\BOOKMARK [1][-]{section.9.5}{Deconvolutional\040Network}{chapter.9}% 259
\BOOKMARK [2][-]{subsection.9.5.1}{Convolutional\040Spare\040Coding}{section.9.5}% 260
\BOOKMARK [2][-]{subsection.9.5.2}{CNN可视化}{section.9.5}% 261
\BOOKMARK [2][-]{subsection.9.5.3}{Upsampling}{section.9.5}% 262
\BOOKMARK [2][-]{subsection.9.5.4}{补充}{section.9.5}% 263
\BOOKMARK [2][-]{subsection.9.5.5}{Deconvolution与Upsample的区别}{section.9.5}% 264
\BOOKMARK [2][-]{subsection.9.5.6}{Deconvolution输出的大小计算}{section.9.5}% 265
\BOOKMARK [2][-]{subsection.9.5.7}{Conv2DTranspose用于成倍的提高分辨率的时候}{section.9.5}% 266
\BOOKMARK [1][-]{section.9.6}{Dilated Network与Deconv Network之间的区别}{chapter.9}% 267
\BOOKMARK [1][-]{section.9.7}{目标检测中的mAP的含义}{chapter.9}% 268
\BOOKMARK [1][-]{section.9.8}{统计学习方法}{chapter.9}% 269
\BOOKMARK [1][-]{section.9.9}{Distillation\040Module}{chapter.9}% 270
\BOOKMARK [2][-]{subsection.9.9.1}{Knowledge\040Distillation}{section.9.9}% 271
\BOOKMARK [2][-]{subsection.9.9.2}{Recurrent\040Knowledge\040Distillation\040Silvia2018Recurrent}{section.9.9}% 272
\BOOKMARK [1][-]{section.9.10}{光流估计中的Average end-point error}{chapter.9}% 273
\BOOKMARK [1][-]{section.9.11}{CNN中的卷及方式汇总}{chapter.9}% 274
\BOOKMARK [2][-]{subsection.9.11.1}{Inception}{section.9.11}% 275
\BOOKMARK [2][-]{subsection.9.11.2}{空洞卷积, Dilation}{section.9.11}% 276
\BOOKMARK [2][-]{subsection.9.11.3}{深度可分离卷积, Depthwise Separable Convolution}{section.9.11}% 277
\BOOKMARK [2][-]{subsection.9.11.4}{可变性卷积}{section.9.11}% 278
\BOOKMARK [2][-]{subsection.9.11.5}{特征重标定卷积}{section.9.11}% 279
\BOOKMARK [2][-]{subsection.9.11.6}{小结-比较}{section.9.11}% 280
\BOOKMARK [1][-]{section.9.12}{全连接与卷积的异同}{chapter.9}% 281
\BOOKMARK [1][-]{section.9.13}{Pooling}{chapter.9}% 282
\BOOKMARK [1][-]{section.9.14}{Local\040Response\040Normalization}{chapter.9}% 283
\BOOKMARK [1][-]{section.9.15}{CNN中感受野的计算}{chapter.9}% 284
\BOOKMARK [1][-]{section.9.16}{神经网络中的初始化}{chapter.9}% 285
\BOOKMARK [2][-]{subsection.9.16.1}{Xavier}{section.9.16}% 286
\BOOKMARK [1][-]{section.9.17}{计算图的后向传播计算}{chapter.9}% 287
\BOOKMARK [2][-]{subsection.9.17.1}{Notes\040on\040CNNs}{section.9.17}% 288
\BOOKMARK [2][-]{subsection.9.17.2}{Pooling层的反向传播}{section.9.17}% 289
\BOOKMARK [1][-]{section.9.18}{神经网络中的Attention机制}{chapter.9}% 290
\BOOKMARK [2][-]{subsection.9.18.1}{Recurrent\040Models\040of\040Visual\040Attention}{section.9.18}% 291
\BOOKMARK [1][-]{section.9.19}{小型网络}{chapter.9}% 292
\BOOKMARK [2][-]{subsection.9.19.1}{理论分析}{section.9.19}% 293
\BOOKMARK [2][-]{subsection.9.19.2}{GCONV\040&\040DWCONV}{section.9.19}% 294
\BOOKMARK [2][-]{subsection.9.19.3}{NiN及相关}{section.9.19}% 295
\BOOKMARK [1][-]{section.9.20}{Deep\040Reinforcement\040Learning}{chapter.9}% 296
\BOOKMARK [1][-]{section.9.21}{为什么Python中要继承object类}{chapter.9}% 297
\BOOKMARK [1][-]{section.9.22}{1*1卷积}{chapter.9}% 298
\BOOKMARK [1][-]{section.9.23}{目标检测中完整流程}{chapter.9}% 299
\BOOKMARK [1][-]{section.9.24}{Batch Size的影响}{chapter.9}% 300
\BOOKMARK [1][-]{section.9.25}{非极大值抑制NMS}{chapter.9}% 301
\BOOKMARK [1][-]{section.9.26}{Bilinear filler初始化ConvTranspose层的权重}{chapter.9}% 302
\BOOKMARK [1][-]{section.9.27}{卷积层输出的尺寸}{chapter.9}% 303
\BOOKMARK [1][-]{section.9.28}{机器学习面试博客总结2018.06.11}{chapter.9}% 304
\BOOKMARK [2][-]{subsection.9.28.1}{大疆}{section.9.28}% 305
\BOOKMARK [2][-]{subsection.9.28.2}{机器学习面试总结}{section.9.28}% 306
\BOOKMARK [1][-]{section.9.29}{花书前两部分总结}{chapter.9}% 307
\BOOKMARK [2][-]{subsection.9.29.1}{第三章}{section.9.29}% 308
\BOOKMARK [2][-]{subsection.9.29.2}{第四章}{section.9.29}% 309
\BOOKMARK [2][-]{subsection.9.29.3}{第五章}{section.9.29}% 310
\BOOKMARK [2][-]{subsection.9.29.4}{第六章}{section.9.29}% 311
\BOOKMARK [2][-]{subsection.9.29.5}{第七章}{section.9.29}% 312
\BOOKMARK [2][-]{subsection.9.29.6}{第八章}{section.9.29}% 313
\BOOKMARK [1][-]{section.9.30}{梯度消失-梯度爆炸 专题}{chapter.9}% 314
\BOOKMARK [2][-]{subsection.9.30.1}{自圆其说的解释}{section.9.30}% 315
\BOOKMARK [1][-]{section.9.31}{ROI\040Pooling}{chapter.9}% 316
\BOOKMARK [1][-]{section.9.32}{深度学习面试100题}{chapter.9}% 317
\BOOKMARK [2][-]{subsection.9.32.1}{Tensorflow计算图}{section.9.32}% 318
\BOOKMARK [2][-]{subsection.9.32.2}{DL调参}{section.9.32}% 319
\BOOKMARK [2][-]{subsection.9.32.3}{为什么CNN在CV、NLP、Sppech、AlphaGo里面都有应用}{section.9.32}% 320
\BOOKMARK [2][-]{subsection.9.32.4}{为什么要引入非线性激励函数}{section.9.32}% 321
\BOOKMARK [2][-]{subsection.9.32.5}{为什么ReLU要好于tanh和sigmoid function}{section.9.32}% 322
\BOOKMARK [2][-]{subsection.9.32.6}{为啥LSTM模型中既存在sigmoid又存在tanh两种激活函数}{section.9.32}% 323
\BOOKMARK [2][-]{subsection.9.32.7}{如何解决RNN梯度爆炸和弥散问题}{section.9.32}% 324
\BOOKMARK [2][-]{subsection.9.32.8}{什么样的数据集不适合深度学习}{section.9.32}% 325
\BOOKMARK [2][-]{subsection.9.32.9}{如何解决梯度消失和梯度膨胀}{section.9.32}% 326
\BOOKMARK [2][-]{subsection.9.32.10}{激活函数的真正意义}{section.9.32}% 327
\BOOKMARK [2][-]{subsection.9.32.11}{梯度下降训练神经网络容易收敛到局部最优，为什么还应用广泛}{section.9.32}% 328
\BOOKMARK [1][-]{section.9.33}{数据的归一化}{chapter.9}% 329
\BOOKMARK [2][-]{subsection.9.33.1}{为什么需要归一化}{section.9.33}% 330
\BOOKMARK [2][-]{subsection.9.33.2}{归一化的方法}{section.9.33}% 331
\BOOKMARK [2][-]{subsection.9.33.3}{小结}{section.9.33}% 332
\BOOKMARK [1][-]{section.9.34}{待续}{chapter.9}% 333
\BOOKMARK [0][-]{chapter.10}{Image\040Processing}{}% 334
\BOOKMARK [1][-]{section.10.1}{Feature\040Extraction}{chapter.10}% 335
\BOOKMARK [2][-]{subsection.10.1.1}{SIFT}{section.10.1}% 336
\BOOKMARK [0][-]{chapter.11}{Feature\040Extraction}{}% 337
\BOOKMARK [1][-]{section.11.1}{Selective\040Search}{chapter.11}% 338
\BOOKMARK [2][-]{subsection.11.1.1}{Efficient\040Graph-Based\040Image\040Segmentation}{section.11.1}% 339
\BOOKMARK [2][-]{subsection.11.1.2}{Selective\040Search}{section.11.1}% 340
\BOOKMARK [1][-]{section.11.2}{Region\040CNN}{chapter.11}% 341
\BOOKMARK [2][-]{subsection.11.2.1}{概述}{section.11.2}% 342
\BOOKMARK [1][-]{section.11.3}{SPP\040Net}{chapter.11}% 343
\BOOKMARK [2][-]{subsection.11.3.1}{背景与相关工作}{section.11.3}% 344
\BOOKMARK [2][-]{subsection.11.3.2}{网络结构}{section.11.3}% 345
\BOOKMARK [2][-]{subsection.11.3.3}{Object\040Detection\040Experiments}{section.11.3}% 346
\BOOKMARK [2][-]{subsection.11.3.4}{Conclusion}{section.11.3}% 347
\BOOKMARK [1][-]{section.11.4}{Fast\040RCNN}{chapter.11}% 348
\BOOKMARK [2][-]{subsection.11.4.1}{ROI-Pooling层的实现-知乎}{section.11.4}% 349
\BOOKMARK [1][-]{section.11.5}{Faster\040RCNN}{chapter.11}% 350
\BOOKMARK [1][-]{section.11.6}{R\040FCN}{chapter.11}% 351
\BOOKMARK [1][-]{section.11.7}{Mask\040RCNN}{chapter.11}% 352
\BOOKMARK [1][-]{section.11.8}{YOLO}{chapter.11}% 353
\BOOKMARK [1][-]{section.11.9}{YOLO\040v2}{chapter.11}% 354
\BOOKMARK [1][-]{section.11.10}{YOLO\040v3}{chapter.11}% 355
\BOOKMARK [1][-]{section.11.11}{SSD}{chapter.11}% 356
\BOOKMARK [1][-]{section.11.12}{DSSD}{chapter.11}% 357
\BOOKMARK [1][-]{section.11.13}{Retina\040Net\040\(Focal\040Loss\)}{chapter.11}% 358
\BOOKMARK [1][-]{section.11.14}{Feature\040Pyramid\040Network}{chapter.11}% 359
\BOOKMARK [2][-]{subsection.11.14.1}{Nearest\040Neighbor\040Interpolation}{section.11.14}% 360
\BOOKMARK [1][-]{section.11.15}{ResNet}{chapter.11}% 361
