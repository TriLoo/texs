\contentsline {chapter}{\numberline {1}Image processing based on CUDA}{3}{chapter.1}
\contentsline {section}{\numberline {1.1}Novel multi-scale retinex with color restoration on graphics processing unit}{3}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Abstract}{3}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}Content}{3}{subsection.1.1.2}
\contentsline {subsection}{\numberline {1.1.3}Parallel optimization strage}{3}{subsection.1.1.3}
\contentsline {subsubsection}{size of thread block and grid}{3}{section*.3}
\contentsline {subsubsection}{Memory access optimization}{4}{section*.4}
\contentsline {subsubsection}{Loop unrolling}{4}{section*.5}
\contentsline {subsection}{\numberline {1.1.4}Conclusion}{4}{subsection.1.1.4}
\contentsline {section}{\numberline {1.2}Image Convolution}{4}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Na\"ive Implementation}{4}{subsection.1.2.1}
\contentsline {subsection}{\numberline {1.2.2}Na\"ive Shared Memory Implementation}{6}{subsection.1.2.2}
\contentsline {subsection}{\numberline {1.2.3}Separable Gaussian Filtering}{8}{subsection.1.2.3}
\contentsline {subsubsection}{Separable Convolution}{8}{section*.8}
\contentsline {subsubsection}{Seperate Gaussian filter}{9}{section*.9}
\contentsline {subsection}{\numberline {1.2.4}Optimizing for memory coalescence}{9}{subsection.1.2.4}
\contentsline {section}{\numberline {1.3}CUDA C Best Practice Guide}{10}{section.1.3}
\contentsline {subsection}{\numberline {1.3.1}Performance Metrics}{10}{subsection.1.3.1}
\contentsline {subsubsection}{Timing}{10}{section*.10}
\contentsline {subsubsection}{Bandwidth}{10}{section*.11}
\contentsline {section}{\numberline {1.4}Npp Library Image Filters}{10}{section.1.4}
\contentsline {subsection}{\numberline {1.4.1}Image Data}{10}{subsection.1.4.1}
\contentsline {subsubsection}{Line Step}{10}{section*.12}
\contentsline {section}{\numberline {1.5}PTX ISA 6.0}{10}{section.1.5}
\contentsline {subsection}{\numberline {1.5.1}PTX Machine Model}{10}{subsection.1.5.1}
\contentsline {subsubsection}{Syntax}{11}{section*.13}
\contentsline {subsubsection}{Source Format}{11}{section*.14}
\contentsline {subsubsection}{Statements}{11}{section*.15}
\contentsline {chapter}{\numberline {2}FPGAs}{13}{chapter.2}
\contentsline {section}{\numberline {2.1}Performance Comparison of FPGA, GPU and CPU in Image Processing 2009}{13}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Abstract}{13}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Content}{14}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Results}{15}{subsection.2.1.3}
\contentsline {subsection}{\numberline {2.1.4}Conclusion}{15}{subsection.2.1.4}
\contentsline {section}{\numberline {2.2}Fast FPGA Prototyping for real-time image processing with very high-level synthesis 2017}{16}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Abstract}{16}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Content}{17}{subsection.2.2.2}
\contentsline {chapter}{\numberline {3}Image Fusion}{19}{chapter.3}
\contentsline {section}{\numberline {3.1}Guided Image Filter 2013}{19}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Abstract}{19}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Content}{19}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}Conclusion}{20}{subsection.3.1.3}
\contentsline {section}{\numberline {3.2}Multiscale Image Fusion Through Guided Filtering}{20}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Abstract}{20}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Contents}{20}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Conclusion}{22}{subsection.3.2.3}
\contentsline {section}{\numberline {3.3}Image Fusion With Guided Filtering}{23}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Abstract}{23}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}Contents}{23}{subsection.3.3.2}
\contentsline {subsubsection}{Guided Filter}{23}{section*.22}
\contentsline {subsection}{\numberline {3.3.3}Fusion Frame}{24}{subsection.3.3.3}
\contentsline {subsection}{\numberline {3.3.4}Conclusion}{24}{subsection.3.3.4}
\contentsline {chapter}{\numberline {4}Saliency Detection}{25}{chapter.4}
\contentsline {section}{\numberline {4.1}Frequency-tuned Salient Region Detection}{25}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Abstract}{25}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Contents}{25}{subsection.4.1.2}
\contentsline {subsubsection}{Related work}{25}{section*.24}
\contentsline {subsection}{\numberline {4.1.3}Conclusion}{26}{subsection.4.1.3}
\contentsline {chapter}{\numberline {5}Semantic SLAM}{27}{chapter.5}
\contentsline {section}{\numberline {5.1}DeLS-3D: Deep Localization and Segmentation with a 2D Semantic Map\cite {WangWang2018DeLS}}{27}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Abstract}{27}{subsection.5.1.1}
\contentsline {subsection}{\numberline {5.1.2}Introduction}{27}{subsection.5.1.2}
\contentsline {subsection}{\numberline {5.1.3}Framework}{28}{subsection.5.1.3}
\contentsline {subsection}{\numberline {5.1.4}Related Work}{28}{subsection.5.1.4}
\contentsline {subsection}{\numberline {5.1.5}Dataset}{29}{subsection.5.1.5}
\contentsline {subsection}{\numberline {5.1.6}Localizing camera and Scene Parsing}{29}{subsection.5.1.6}
\contentsline {subsubsection}{Render a label map from a camera pose}{29}{section*.28}
\contentsline {subsubsection}{Camera Localization rectification with road prior}{30}{section*.29}
\contentsline {subsubsection}{Video Parsing with Pose Guidance}{30}{section*.30}
\contentsline {subsection}{\numberline {5.1.7}Experiment}{30}{subsection.5.1.7}
\contentsline {subsection}{\numberline {5.1.8}Conclusion}{31}{subsection.5.1.8}
\contentsline {section}{\numberline {5.2}PAD-Net: Multi-Task Guided Prediction-and-Distillation Network for Simultaneous Depth and Scene Parsing \cite {Xu2018PADNet}}{31}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Abstract}{31}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Analysis}{31}{subsection.5.2.2}
\contentsline {subsubsection}{Effect of Direct Multi-task Learning}{31}{section*.32}
\contentsline {subsubsection}{Effect of Multi-modal Distillation}{31}{section*.33}
\contentsline {subsubsection}{Importance of Intermediate Supervision and Tasks}{31}{section*.34}
\contentsline {section}{\numberline {5.3}RNN for Learning Dense Depth and Ego-Motion from Video}{32}{section.5.3}
\contentsline {subsection}{\numberline {5.3.1}Abstract}{32}{subsection.5.3.1}
\contentsline {subsection}{\numberline {5.3.2}Introduction \& Related Works}{32}{subsection.5.3.2}
\contentsline {subsection}{\numberline {5.3.3}Network Architecture}{33}{subsection.5.3.3}
\contentsline {subsection}{\numberline {5.3.4}Training}{34}{subsection.5.3.4}
\contentsline {subsubsection}{Loss Function}{34}{section*.37}
\contentsline {subsection}{\numberline {5.3.5}Experiments}{35}{subsection.5.3.5}
\contentsline {subsection}{\numberline {5.3.6}Ablation Studies}{35}{subsection.5.3.6}
\contentsline {subsubsection}{Conclusions}{35}{section*.38}
\contentsline {section}{\numberline {5.4}DA-RNN}{35}{section.5.4}
\contentsline {subsection}{\numberline {5.4.1}Related Works}{36}{subsection.5.4.1}
\contentsline {subsection}{\numberline {5.4.2}Methods}{36}{subsection.5.4.2}
\contentsline {subsection}{\numberline {5.4.3}Experiments}{36}{subsection.5.4.3}
\contentsline {subsection}{\numberline {5.4.4}Conclusion}{36}{subsection.5.4.4}
\contentsline {section}{\numberline {5.5}SemanticFusion: Dense 3D Semantic Mapping with CNNs}{36}{section.5.5}
\contentsline {subsection}{\numberline {5.5.1}Introduction \& Related Works}{36}{subsection.5.5.1}
\contentsline {subsection}{\numberline {5.5.2}Method}{37}{subsection.5.5.2}
\contentsline {subsubsection}{SLAM Mapping}{37}{section*.40}
\contentsline {subsubsection}{CNN Architecture}{38}{section*.41}
\contentsline {subsubsection}{Incremental Semantic Label Fusion}{38}{section*.42}
\contentsline {subsubsection}{Map Regularisation}{38}{section*.43}
\contentsline {subsection}{\numberline {5.5.3}Experiments}{38}{subsection.5.5.3}
\contentsline {subsection}{\numberline {5.5.4}总结}{38}{subsection.5.5.4}
\contentsline {section}{\numberline {5.6}Meaningful Maps with Object-Oriented Semantic Mapping}{39}{section.5.6}
\contentsline {subsection}{\numberline {5.6.1}Introduction \& Related Works}{39}{subsection.5.6.1}
\contentsline {subsubsection}{Semantic Mapping}{39}{section*.44}
\contentsline {subsubsection}{Object Detection and Semantic Segmentation}{39}{section*.45}
\contentsline {subsection}{\numberline {5.6.2}Object Oriented Semantic Mapping}{39}{subsection.5.6.2}
\contentsline {subsubsection}{Object Detection for Semantic Mapping}{39}{section*.47}
\contentsline {subsubsection}{3D Segmentation}{39}{section*.48}
\contentsline {subsubsection}{Data Association}{39}{section*.49}
\contentsline {subsubsection}{Object Model Update}{41}{section*.50}
\contentsline {subsubsection}{Map Generation}{41}{section*.52}
\contentsline {subsection}{\numberline {5.6.3}总结}{42}{subsection.5.6.3}
\contentsline {section}{\numberline {5.7}LiteFlowNet}{42}{section.5.7}
\contentsline {subsection}{\numberline {5.7.1}背景知识}{42}{subsection.5.7.1}
\contentsline {subsection}{\numberline {5.7.2}Related Works}{43}{subsection.5.7.2}
\contentsline {subsubsection}{Variational Methods}{43}{section*.53}
\contentsline {subsubsection}{Machine Learning Methods}{43}{section*.54}
\contentsline {subsubsection}{CNN-based Methods}{44}{section*.55}
\contentsline {subsubsection}{Establish Point Correspondence}{44}{section*.56}
\contentsline {subsection}{\numberline {5.7.3}LiteFlowNet}{44}{subsection.5.7.3}
\contentsline {subsubsection}{Pyramid Feature Extraction}{45}{section*.58}
\contentsline {subsubsection}{Feature Warping (f-warp)}{45}{section*.59}
\contentsline {subsubsection}{Cascaded Flow Interface}{45}{section*.60}
\contentsline {subsubsection}{Flow Regularization}{47}{section*.62}
\contentsline {subsection}{\numberline {5.7.4}Ablation Study}{47}{subsection.5.7.4}
\contentsline {subsubsection}{Feature Warping}{47}{section*.63}
\contentsline {subsubsection}{Descriptor Matching}{47}{section*.64}
\contentsline {subsubsection}{Sub-Pixel Refinement}{47}{section*.65}
\contentsline {subsection}{\numberline {5.7.5}Regularization}{48}{subsection.5.7.5}
\contentsline {subsection}{\numberline {5.7.6}Conclusion}{48}{subsection.5.7.6}
\contentsline {section}{\numberline {5.8}小结}{48}{section.5.8}
\contentsline {section}{\numberline {5.9}ExFuse: Enhancing Feature Fusion for Semantic Segmentation}{48}{section.5.9}
\contentsline {subsection}{\numberline {5.9.1}要解决的问题}{48}{subsection.5.9.1}
\contentsline {subsection}{\numberline {5.9.2}Method}{48}{subsection.5.9.2}
\contentsline {subsubsection}{在底层中加入更多的语义信息}{49}{section*.67}
\contentsline {subsubsection}{在高层中加入更多的空间信息}{49}{section*.69}
\contentsline {section}{\numberline {5.10}Multi-View Deep Learning for Consistent Semantic Mapping with RGB-D Cameras}{50}{section.5.10}
\contentsline {subsection}{\numberline {5.10.1}Introduction \& Related Works}{50}{subsection.5.10.1}
\contentsline {subsubsection}{Image based Semantic Segmentation}{51}{section*.70}
\contentsline {subsubsection}{Semantic SLAM}{51}{section*.71}
\contentsline {subsubsection}{Multi-View Semantic Segmentation}{51}{section*.72}
\contentsline {subsection}{\numberline {5.10.2}CNN Architecture For Semantic Segmentation}{51}{subsection.5.10.2}
\contentsline {subsection}{\numberline {5.10.3}Multi-View Consistent Learning and Prediction}{52}{subsection.5.10.3}
\contentsline {subsubsection}{Multi-view Data Associate Through Warping}{52}{section*.74}
\contentsline {subsubsection}{Consistency Through Warp Augmentation}{52}{section*.75}
\contentsline {subsubsection}{Consistency Through Bayesian Fusion}{52}{section*.76}
\contentsline {subsubsection}{Consistency Through Multi-View Max-Pooling}{52}{section*.77}
\contentsline {subsection}{\numberline {5.10.4}Experiments}{53}{subsection.5.10.4}
\contentsline {subsection}{\numberline {5.10.5}总结}{53}{subsection.5.10.5}
\contentsline {section}{\numberline {5.11}MaskFusion}{53}{section.5.11}
\contentsline {subsection}{\numberline {5.11.1}背景及相关工作}{53}{subsection.5.11.1}
\contentsline {subsubsection}{Dense RGB-D SLAM}{54}{section*.78}
\contentsline {subsubsection}{Scene Segmentation \& Semantic Scene Segmentation}{54}{section*.79}
\contentsline {subsubsection}{Semantic SLAM \& Dynamic SLAM}{54}{section*.80}
\contentsline {subsection}{\numberline {5.11.2}System Design}{55}{subsection.5.11.2}
\contentsline {subsubsection}{System Overview}{55}{section*.81}
\contentsline {subsubsection}{Multi-Object SLAM}{55}{section*.83}
\contentsline {subsubsection}{Segmentation}{57}{section*.84}
\contentsline {subsection}{\numberline {5.11.3}Evaluation}{57}{subsection.5.11.3}
\contentsline {subsection}{\numberline {5.11.4}总结}{57}{subsection.5.11.4}
\contentsline {section}{\numberline {5.12}小结 2}{58}{section.5.12}
\contentsline {section}{\numberline {5.13}CNN-SLAM}{58}{section.5.13}
\contentsline {section}{\numberline {5.14}图像语义分割之FCN和CRF}{58}{section.5.14}
\contentsline {subsection}{\numberline {5.14.1}前端FCN}{59}{subsection.5.14.1}
\contentsline {subsubsection}{FCN}{59}{section*.86}
\contentsline {subsubsection}{SegNet/DecovNet}{59}{section*.87}
\contentsline {subsection}{\numberline {5.14.2}DeepLab}{59}{subsection.5.14.2}
\contentsline {subsection}{\numberline {5.14.3}后端优化CRF/MRF}{61}{subsection.5.14.3}
\contentsline {subsubsection}{全连接CRF， DenseCRF}{61}{section*.90}
\contentsline {subsubsection}{CRFasRNN}{61}{section*.91}
\contentsline {subsubsection}{马尔科夫随机场， MRF}{61}{section*.92}
\contentsline {subsubsection}{高斯条件随机场， G-CRF}{61}{section*.93}
\contentsline {subsection}{\numberline {5.14.4}小结}{61}{subsection.5.14.4}
\contentsline {section}{\numberline {5.15}Learning Deconvolution Network for Semantic}{62}{section.5.15}
\contentsline {subsubsection}{Instance-wise Segmentation}{63}{section*.95}
\contentsline {section}{\numberline {5.16}ReSeg 2015}{63}{section.5.16}
\contentsline {subsection}{\numberline {5.16.1}背景 \& 相关工作}{63}{subsection.5.16.1}
\contentsline {subsection}{\numberline {5.16.2}Model Description}{63}{subsection.5.16.2}
\contentsline {subsubsection}{Recurrent layer}{63}{section*.96}
\contentsline {subsubsection}{Upsampling layer}{63}{section*.98}
\contentsline {subsection}{\numberline {5.16.3}实验结果}{65}{subsection.5.16.3}
\contentsline {subsection}{\numberline {5.16.4}总结}{65}{subsection.5.16.4}
\contentsline {section}{\numberline {5.17}U-Net}{65}{section.5.17}
\contentsline {subsection}{\numberline {5.17.1}Network Architecture}{65}{subsection.5.17.1}
\contentsline {subsection}{\numberline {5.17.2}Conclusion}{66}{subsection.5.17.2}
\contentsline {subsection}{\numberline {5.17.3}补充}{66}{subsection.5.17.3}
\contentsline {section}{\numberline {5.18}Semantic Visual Localization}{67}{section.5.18}
\contentsline {subsection}{\numberline {5.18.1}背景 \& 相关工作}{67}{subsection.5.18.1}
\contentsline {subsection}{\numberline {5.18.2}Semantic Visual Localization}{68}{subsection.5.18.2}
\contentsline {subsection}{\numberline {5.18.3}Experiments}{69}{subsection.5.18.3}
\contentsline {subsection}{\numberline {5.18.4}Conclusions}{70}{subsection.5.18.4}
\contentsline {section}{\numberline {5.19}小结3}{70}{section.5.19}
\contentsline {section}{\numberline {5.20}StaticFusion}{70}{section.5.20}
\contentsline {subsection}{\numberline {5.20.1}背景}{70}{subsection.5.20.1}
\contentsline {subsection}{\numberline {5.20.2}动态场景下SLAM系统的相关工作}{70}{subsection.5.20.2}
\contentsline {subsection}{\numberline {5.20.3}Framework和Notation}{71}{subsection.5.20.3}
\contentsline {subsubsection}{第二步的计算}{72}{section*.102}
\contentsline {section}{\numberline {5.21}Convolutional CRFs for Semantic Segmentation}{72}{section.5.21}
\contentsline {subsection}{\numberline {5.21.1}背景 \& 相关工作}{72}{subsection.5.21.1}
\contentsline {subsection}{\numberline {5.21.2}Fully Connected CRFs}{73}{subsection.5.21.2}
\contentsline {subsubsection}{Full CRF的Mean field inference}{74}{section*.103}
\contentsline {subsection}{\numberline {5.21.3}Convolutional CRFs}{74}{subsection.5.21.3}
\contentsline {subsubsection}{Efficient Message Passing in ConvCRFs }{74}{section*.105}
\contentsline {subsubsection}{Additional implementation details}{75}{section*.106}
\contentsline {subsection}{\numberline {5.21.4}总结}{75}{subsection.5.21.4}
\contentsline {section}{\numberline {5.22}Co-Fusion}{75}{section.5.22}
\contentsline {section}{\numberline {5.23}Squeeze-and-Excitation Networks}{75}{section.5.23}
\contentsline {section}{\numberline {5.24}Deep Multi-scale Architectures For Monocular Depth Estimation}{76}{section.5.24}
\contentsline {subsection}{\numberline {5.24.1}背景与相关工作}{76}{subsection.5.24.1}
\contentsline {section}{\numberline {5.25}Depth Map Prediction from a single image usign a multi-Scale Deep Network}{77}{section.5.25}
\contentsline {section}{\numberline {5.26}Mask R-CNN}{78}{section.5.26}
\contentsline {subsection}{\numberline {5.26.1}研究现状与相关背景}{79}{subsection.5.26.1}
\contentsline {subsection}{\numberline {5.26.2}Mask RCNN}{79}{subsection.5.26.2}
\contentsline {subsection}{\numberline {5.26.3}实验}{80}{subsection.5.26.3}
\contentsline {subsection}{\numberline {5.26.4}总结}{80}{subsection.5.26.4}
\contentsline {section}{\numberline {5.27}Learning to segment every thing}{80}{section.5.27}
\contentsline {section}{\numberline {5.28}Path aggregation network for instance segmentation}{82}{section.5.28}
\contentsline {section}{\numberline {5.29}End-to-End Instance Segmentation with Recurrent Attention}{82}{section.5.29}
\contentsline {section}{\numberline {5.30}Fully Convolutional Instance-aware Semantic Segmentation}{82}{section.5.30}
\contentsline {subsection}{\numberline {5.30.1}背景与相关现状}{82}{subsection.5.30.1}
\contentsline {subsection}{\numberline {5.30.2}Our Approach}{83}{subsection.5.30.2}
\contentsline {section}{\numberline {5.31}TernausNetV2: Fully Convolutional Network for Instance Segmentation}{83}{section.5.31}
\contentsline {subsection}{\numberline {5.31.1}背景及相关工作}{83}{subsection.5.31.1}
\contentsline {subsection}{\numberline {5.31.2}Model}{83}{subsection.5.31.2}
\contentsline {subsection}{\numberline {5.31.3}Training}{83}{subsection.5.31.3}
\contentsline {subsection}{\numberline {5.31.4}常用数据集}{84}{subsection.5.31.4}
\contentsline {subsection}{\numberline {5.31.5}KITTI}{84}{subsection.5.31.5}
\contentsline {subsection}{\numberline {5.31.6}官网资源介绍}{84}{subsection.5.31.6}
\contentsline {subsection}{\numberline {5.31.7}详述}{85}{subsection.5.31.7}
\contentsline {subsubsection}{组织形式}{85}{section*.113}
\contentsline {subsubsection}{Development Kit}{86}{section*.115}
\contentsline {subsection}{\numberline {5.31.8}Cityscape}{86}{subsection.5.31.8}
\contentsline {subsection}{\numberline {5.31.9}TUM}{86}{subsection.5.31.9}
\contentsline {section}{\numberline {5.32}实例分割-图像分割2018.06.11博客总结}{86}{section.5.32}
\contentsline {subsection}{\numberline {5.32.1}Mask R-CNN狙击目标实例分割}{86}{subsection.5.32.1}
\contentsline {subsubsection}{什么是实例分割}{86}{section*.116}
\contentsline {subsubsection}{Mask RCNN介绍}{86}{section*.117}
\contentsline {subsubsection}{Mask RCNN的工作机理}{87}{section*.118}
\contentsline {subsubsection}{Tensorflow + Keras实现实例分割}{87}{section*.119}
\contentsline {section}{\numberline {5.33}无需Proposal的实例分割论文}{87}{section.5.33}
\contentsline {section}{\numberline {5.34}Learning Rich Features from RGB-D Images for Object Detection and Segmentation}{88}{section.5.34}
\contentsline {section}{\numberline {5.35}Multimodal Deep Learning for Robust RGB-D Object Recognition}{88}{section.5.35}
\contentsline {section}{\numberline {5.36}3D Graph Neural Networks for RGBD Semantic Segmentation}{89}{section.5.36}
\contentsline {section}{\numberline {5.37}RefineNet}{89}{section.5.37}
\contentsline {subsection}{\numberline {5.37.1}引言中的重要几点}{89}{subsection.5.37.1}
\contentsline {subsection}{\numberline {5.37.2}算法思想}{90}{subsection.5.37.2}
\contentsline {subsection}{\numberline {5.37.3}实验部分}{90}{subsection.5.37.3}
\contentsline {subsection}{\numberline {5.37.4}小结}{90}{subsection.5.37.4}
\contentsline {section}{\numberline {5.38}Residual Attention Network For Image Classification}{90}{section.5.38}
\contentsline {subsection}{\numberline {5.38.1}背景及相关工作}{90}{subsection.5.38.1}
\contentsline {subsection}{\numberline {5.38.2}Residual Attention Network}{91}{subsection.5.38.2}
\contentsline {subsubsection}{Attention Residual Learning}{91}{section*.120}
\contentsline {subsubsection}{Soft Mask Branch}{92}{section*.121}
\contentsline {subsubsection}{Spatial Attention And Channel Attention}{92}{section*.122}
\contentsline {subsection}{\numberline {5.38.3}实验}{93}{subsection.5.38.3}
\contentsline {subsection}{\numberline {5.38.4}总结}{93}{subsection.5.38.4}
\contentsline {section}{\numberline {5.39}Object-based RGBD Image Co-segmentation with Mutex Constraint}{93}{section.5.39}
\contentsline {section}{\numberline {5.40}RedNet: Residual Encoder-Decoder Network for indoor .RGB-D Semantic Segmentation}{94}{section.5.40}
\contentsline {section}{\numberline {5.41}RDFNet: RGB-D Multi-level Residual Feature fusion for Indoor Sematnic Segmentation}{94}{section.5.41}
\contentsline {section}{\numberline {5.42}Progressively Complementarity-aware Fusion Network for RGB-D Salient Object Detection}{94}{section.5.42}
\contentsline {section}{\numberline {5.43}Semantic-Guided Multi-level RGB-D Feature Fusion for Indoor Semantic segmentation}{94}{section.5.43}
\contentsline {section}{\numberline {5.44}Learning Common and Specific Features for RGB-D Semantic Segmentation with Deconvolutional Networks}{94}{section.5.44}
\contentsline {chapter}{\numberline {6}Open Set Recognition}{95}{chapter.6}
\contentsline {section}{\numberline {6.1}GAN}{95}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}GAN 原理笔记}{95}{subsection.6.1.1}
\contentsline {subsubsection}{GAN原理}{95}{section*.123}
\contentsline {subsubsection}{GAN公式}{96}{section*.124}
\contentsline {subsubsection}{训练过程}{96}{section*.125}
\contentsline {subsubsection}{Loss Function中的两个小问题}{97}{section*.127}
\contentsline {section}{\numberline {6.2}从头开始GAN}{97}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}定义}{98}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}DCGAN： Deep Convolution GAN}{98}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}CGAN: Conditional Generative Adversarial Nets}{99}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}InfoGAN}{99}{subsection.6.2.4}
\contentsline {section}{\numberline {6.3}Generative Adversarial Nets}{100}{section.6.3}
\contentsline {section}{\numberline {6.4}Towards Open Set Deep Networks}{100}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Introduction \& Related Works}{100}{subsection.6.4.1}
\contentsline {section}{\numberline {6.5}Probability Models for Open Set Recognition}{100}{section.6.5}
\contentsline {subsection}{\numberline {6.5.1}背景及相关工作}{101}{subsection.6.5.1}
\contentsline {section}{\numberline {6.6}Meta Recognition}{101}{section.6.6}
\contentsline {subsection}{\numberline {6.6.1}该死的Fisher-Tippet Theorem}{101}{subsection.6.6.1}
\contentsline {subsubsection}{Extreme Value Theory}{102}{section*.129}
\contentsline {subsection}{\numberline {6.6.2}Weibull Distribution}{102}{subsection.6.6.2}
\contentsline {chapter}{\numberline {7}MXNet}{103}{chapter.7}
\contentsline {section}{\numberline {7.1}MXNet System Overview}{103}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}MXNet System Architecture}{103}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}MXNet System Components}{104}{subsection.7.1.2}
\contentsline {subsubsection}{Execution Engine}{104}{section*.130}
\contentsline {subsubsection}{Operators in MXNet}{104}{section*.131}
\contentsline {subsubsection}{Operator Interface}{104}{section*.132}
\contentsline {subsubsection}{Operator Property}{105}{section*.133}
\contentsline {subsubsection}{Create an Operator from the Operator Property}{106}{section*.134}
\contentsline {section}{\numberline {7.2}Optimizing Memory Consumption in DL}{106}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Computation Graph}{106}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}What Can be Optimized?}{108}{subsection.7.2.2}
\contentsline {subsubsection}{In-place Operations}{108}{section*.138}
\contentsline {subsubsection}{Standard Memory Sharing}{108}{section*.139}
\contentsline {subsection}{\numberline {7.2.3}Memory Allocation Algorithm}{109}{subsection.7.2.3}
\contentsline {subsection}{\numberline {7.2.4}Static vs. Dynamic Allocation}{110}{subsection.7.2.4}
\contentsline {subsection}{\numberline {7.2.5}Memory Allocation for Parallel Operations}{110}{subsection.7.2.5}
\contentsline {subsubsection}{Be Correct and Safe First}{110}{section*.144}
\contentsline {subsubsection}{Try to Allow More Parallelization}{111}{section*.145}
\contentsline {subsection}{\numberline {7.2.6}How Much Can we Save ?}{112}{subsection.7.2.6}
\contentsline {subsection}{\numberline {7.2.7}References}{112}{subsection.7.2.7}
\contentsline {section}{\numberline {7.3}Deep Learning Programming Style}{112}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Symbolic vs. Imperative Program}{112}{subsection.7.3.1}
\contentsline {subsection}{\numberline {7.3.2}Imperative Programs Tend to be More Flexible}{112}{subsection.7.3.2}
\contentsline {subsection}{\numberline {7.3.3}Symbolic Programs Tend to be More Efficient}{113}{subsection.7.3.3}
\contentsline {subsection}{\numberline {7.3.4}Case Study: Backprop and AutoDiff}{113}{subsection.7.3.4}
\contentsline {subsubsection}{基于命令式编程的自动求导}{113}{section*.148}
\contentsline {subsubsection}{基于符号式编程的自动求导}{114}{section*.149}
\contentsline {subsubsection}{Analysis}{114}{section*.150}
\contentsline {subsection}{\numberline {7.3.5}Model Checkpoint}{114}{subsection.7.3.5}
\contentsline {subsection}{\numberline {7.3.6}Big vs. Small Operations}{114}{subsection.7.3.6}
\contentsline {subsection}{\numberline {7.3.7}Mix The Approaches}{115}{subsection.7.3.7}
\contentsline {section}{\numberline {7.4}Dependency Engine for Deep Learning}{116}{section.7.4}
\contentsline {subsection}{\numberline {7.4.1}Problems in Dependency Scheduling}{116}{subsection.7.4.1}
\contentsline {subsubsection}{Design a Generic Dependency Engine}{116}{section*.151}
\contentsline {subsection}{\numberline {7.4.2}Implementing the Generic Dependency Engine}{117}{subsection.7.4.2}
\contentsline {subsection}{\numberline {7.4.3}Discussion}{118}{subsection.7.4.3}
\contentsline {section}{\numberline {7.5}Designing Efficient Data Loaders for DL}{118}{section.7.5}
\contentsline {subsection}{\numberline {7.5.1}Design Insight}{118}{subsection.7.5.1}
\contentsline {subsubsection}{Data Preparation}{118}{section*.155}
\contentsline {subsubsection}{Data Loading}{118}{section*.156}
\contentsline {subsection}{\numberline {7.5.2}Data Format}{119}{subsection.7.5.2}
\contentsline {subsubsection}{Access Arbitrary Parts of Data}{120}{section*.159}
\contentsline {subsection}{\numberline {7.5.3}Data Loading and Preprocessing}{120}{subsection.7.5.3}
\contentsline {subsubsection}{Loading and Preprocessing on the Fly}{120}{section*.160}
\contentsline {subsubsection}{Hide IO Cost Using Threadediter}{120}{section*.162}
\contentsline {subsection}{\numberline {7.5.4}MXNet IO Python Interface}{120}{subsection.7.5.4}
\contentsline {section}{\numberline {7.6}Except Handling in MXNet}{121}{section.7.6}
\contentsline {subsubsection}{Exception Handling for Iterators}{122}{section*.164}
\contentsline {subsubsection}{Except Handling for Operators}{122}{section*.165}
\contentsline {section}{\numberline {7.7}MXNet-Gluon创建模型}{122}{section.7.7}
\contentsline {subsection}{\numberline {7.7.1}模型构造}{122}{subsection.7.7.1}
\contentsline {subsubsection}{两种稍微不同的实现}{122}{section*.166}
\contentsline {subsection}{\numberline {7.7.2}自定义层}{124}{subsection.7.7.2}
\contentsline {subsubsection}{带参数的自定义层}{124}{section*.167}
\contentsline {subsection}{\numberline {7.7.3}实际例子}{124}{subsection.7.7.3}
\contentsline {subsubsection}{ResNet}{124}{section*.168}
\contentsline {subsubsection}{DenseNet}{126}{section*.169}
\contentsline {section}{\numberline {7.8}MXNet中的Deconvolution}{126}{section.7.8}
\contentsline {section}{\numberline {7.9}MXNet读取训练数据}{126}{section.7.9}
\contentsline {subsection}{\numberline {7.9.1}使用mx.io读取数据}{127}{subsection.7.9.1}
\contentsline {subsubsection}{从内存中读取}{127}{section*.170}
\contentsline {subsubsection}{从.csv文件中读取数据}{128}{section*.171}
\contentsline {subsubsection}{使用mx.io.ImageRecordIter接口，需要定制KVStore}{128}{section*.172}
\contentsline {subsection}{\numberline {7.9.2}常用的系统提供的接口函数}{129}{subsection.7.9.2}
\contentsline {subsection}{\numberline {7.9.3}使用mx.image读取数据}{129}{subsection.7.9.3}
\contentsline {subsection}{\numberline {7.9.4}使用Gluon接口读取数据}{130}{subsection.7.9.4}
\contentsline {subsubsection}{产生Dataset}{130}{section*.173}
\contentsline {subsubsection}{产生Mini-batch iterator}{131}{section*.174}
\contentsline {section}{\numberline {7.10}Gluon中的数据结构}{131}{section.7.10}
\contentsline {section}{\numberline {7.11}MXNet中的Confusing参数}{132}{section.7.11}
\contentsline {subsection}{\numberline {7.11.1}mx.symbol.reshape}{132}{subsection.7.11.1}
\contentsline {subsection}{\numberline {7.11.2}mx.symbol.transpose}{132}{subsection.7.11.2}
\contentsline {section}{\numberline {7.12}UpSample In MXNet}{133}{section.7.12}
\contentsline {subsection}{\numberline {7.12.1}总结}{135}{subsection.7.12.1}
\contentsline {section}{\numberline {7.13}MXNet中设置层的学习率}{135}{section.7.13}
\contentsline {section}{\numberline {7.14}SoftmaxCrossEntropyLoss释疑}{135}{section.7.14}
\contentsline {section}{\numberline {7.15}MXNet中的3D CNN}{136}{section.7.15}
\contentsline {subsection}{\numberline {7.15.1}应该怎么理解3D CNN}{136}{subsection.7.15.1}
\contentsline {section}{\numberline {7.16}向MXNet添加新的操作}{136}{section.7.16}
\contentsline {subsection}{\numberline {7.16.1}添加新的Operator}{136}{subsection.7.16.1}
\contentsline {subsubsection}{自定义Op}{136}{section*.175}
\contentsline {subsubsection}{CustomOp类}{137}{section*.176}
\contentsline {subsubsection}{PythonOp类}{139}{section*.177}
\contentsline {subsection}{\numberline {7.16.2}添加新的Layer}{139}{subsection.7.16.2}
\contentsline {subsubsection}{如何创建新的网络层-CSDN}{140}{section*.178}
\contentsline {subsubsection}{MXNet添加新层-CSDN}{141}{section*.179}
\contentsline {section}{\numberline {7.17}关于MXNet里面的register修饰符}{142}{section.7.17}
\contentsline {subsection}{\numberline {7.17.1}调用顺序-CSDN博客}{142}{subsection.7.17.1}
\contentsline {subsection}{\numberline {7.17.2}Python中的装饰器之register}{142}{subsection.7.17.2}
\contentsline {chapter}{\numberline {8}GPU Optimization in DL}{143}{chapter.8}
\contentsline {section}{\numberline {8.1}In-Place Activated BatchNorm for Memory-Optimized Training of DNNs}{143}{section.8.1}
\contentsline {section}{\numberline {8.2}Training deep nets with sublinear memory cost}{143}{section.8.2}
\contentsline {section}{\numberline {8.3}Memory-efficient backpropagation through time}{143}{section.8.3}
\contentsline {section}{\numberline {8.4}The Reversible Residual Network: Backpropagation Without Storing Activations}{143}{section.8.4}
\contentsline {section}{\numberline {8.5}}{143}{section.8.5}
\contentsline {chapter}{\numberline {9}Tips in DL}{145}{chapter.9}
\contentsline {section}{\numberline {9.1}Enlarge the FOV}{145}{section.9.1}
\contentsline {section}{\numberline {9.2}Upsampling}{145}{section.9.2}
\contentsline {section}{\numberline {9.3}Multiscale Ability}{146}{section.9.3}
\contentsline {section}{\numberline {9.4}Dilated Convolution}{146}{section.9.4}
\contentsline {section}{\numberline {9.5}Deconvolutional Network}{147}{section.9.5}
\contentsline {subsection}{\numberline {9.5.1}Convolutional Spare Coding}{147}{subsection.9.5.1}
\contentsline {subsection}{\numberline {9.5.2}CNN可视化}{147}{subsection.9.5.2}
\contentsline {subsection}{\numberline {9.5.3}Upsampling}{148}{subsection.9.5.3}
\contentsline {subsection}{\numberline {9.5.4}补充}{148}{subsection.9.5.4}
\contentsline {subsection}{\numberline {9.5.5}Deconvolution与Upsample的区别}{148}{subsection.9.5.5}
\contentsline {subsubsection}{理解深度学习中的Deconvolution Networks}{149}{section*.183}
\contentsline {subsection}{\numberline {9.5.6}Deconvolution输出的大小计算}{150}{subsection.9.5.6}
\contentsline {subsection}{\numberline {9.5.7}Conv2DTranspose用于成倍的提高分辨率的时候}{150}{subsection.9.5.7}
\contentsline {section}{\numberline {9.6}Dilated Network与Deconv Network之间的区别}{151}{section.9.6}
\contentsline {section}{\numberline {9.7}目标检测中的mAP的含义}{151}{section.9.7}
\contentsline {section}{\numberline {9.8}统计学习方法}{152}{section.9.8}
\contentsline {section}{\numberline {9.9}Distillation Module}{152}{section.9.9}
\contentsline {subsection}{\numberline {9.9.1}Knowledge Distillation}{153}{subsection.9.9.1}
\contentsline {subsubsection}{什么是Distilling the knowledge}{153}{section*.187}
\contentsline {subsubsection}{Disilling the knowledge in a Neural Network}{153}{section*.188}
\contentsline {subsection}{\numberline {9.9.2}Recurrent Knowledge Distillation \cite {Silvia2018Recurrent}}{153}{subsection.9.9.2}
\contentsline {section}{\numberline {9.10}光流估计中的Average end-point error}{153}{section.9.10}
\contentsline {section}{\numberline {9.11}CNN中的卷及方式汇总}{153}{section.9.11}
\contentsline {subsection}{\numberline {9.11.1}Inception}{153}{subsection.9.11.1}
\contentsline {subsection}{\numberline {9.11.2}空洞卷积, Dilation}{154}{subsection.9.11.2}
\contentsline {subsection}{\numberline {9.11.3}深度可分离卷积, Depthwise Separable Convolution}{154}{subsection.9.11.3}
\contentsline {subsection}{\numberline {9.11.4}可变性卷积}{156}{subsection.9.11.4}
\contentsline {subsection}{\numberline {9.11.5}特征重标定卷积}{158}{subsection.9.11.5}
\contentsline {subsection}{\numberline {9.11.6}小结-比较}{158}{subsection.9.11.6}
\contentsline {section}{\numberline {9.12}全连接与卷积的异同}{160}{section.9.12}
\contentsline {section}{\numberline {9.13}Pooling}{160}{section.9.13}
\contentsline {subsubsection}{Global Average Pooling}{160}{section*.197}
\contentsline {subsubsection}{Unpooling}{160}{section*.198}
\contentsline {section}{\numberline {9.14}Local Response Normalization}{161}{section.9.14}
\contentsline {subsubsection}{到底什么是LRN}{161}{section*.200}
\contentsline {subsubsection}{如何实现LRN}{161}{section*.201}
\contentsline {section}{\numberline {9.15}CNN中感受野的计算}{162}{section.9.15}
\contentsline {subsubsection}{具体的例子}{162}{section*.202}
\contentsline {subsubsection}{Stride的计算}{163}{section*.203}
\contentsline {subsubsection}{专业的计算}{163}{section*.204}
\contentsline {section}{\numberline {9.16}神经网络中的初始化}{166}{section.9.16}
\contentsline {subsubsection}{回答一}{166}{section*.207}
\contentsline {subsection}{\numberline {9.16.1}Xavier}{166}{subsection.9.16.1}
\contentsline {section}{\numberline {9.17}计算图的后向传播计算}{167}{section.9.17}
\contentsline {subsubsection}{简单的说明}{167}{section*.208}
\contentsline {subsection}{\numberline {9.17.1}Notes on CNNs}{168}{subsection.9.17.1}
\contentsline {subsubsection}{CNN的目标函数，包含Weight Decay的形式}{168}{section*.210}
\contentsline {subsubsection}{求解输出层的误差敏感项}{169}{section*.211}
\contentsline {subsubsection}{当卷积层的下一层是Pooling层时，求解卷积层的误差敏感项}{170}{section*.213}
\contentsline {subsubsection}{当Pooling的下一层为卷积层时，求该Pooling层的误差敏感项}{172}{section*.216}
\contentsline {subsection}{\numberline {9.17.2}Pooling层的反向传播}{172}{subsection.9.17.2}
\contentsline {section}{\numberline {9.18}神经网络中的Attention机制}{172}{section.9.18}
\contentsline {subsection}{\numberline {9.18.1}Recurrent Models of Visual Attention}{172}{subsection.9.18.1}
\contentsline {subsubsection}{The Recurrent Attention Model - RAM }{173}{section*.217}
\contentsline {subsubsection}{总结}{174}{section*.219}
\contentsline {section}{\numberline {9.19}小型网络}{174}{section.9.19}
\contentsline {subsection}{\numberline {9.19.1}理论分析}{174}{subsection.9.19.1}
\contentsline {subsection}{\numberline {9.19.2}GCONV \& DWCONV}{174}{subsection.9.19.2}
\contentsline {subsection}{\numberline {9.19.3}NiN及相关}{175}{subsection.9.19.3}
\contentsline {section}{\numberline {9.20}Deep Reinforcement Learning}{175}{section.9.20}
\contentsline {section}{\numberline {9.21}为什么Python中要继承object类}{175}{section.9.21}
\contentsline {subsubsection}{Python 2.x story}{175}{section*.220}
\contentsline {subsubsection}{Python 3.x story}{176}{section*.221}
\contentsline {subsubsection}{Choose which one}{176}{section*.222}
\contentsline {section}{\numberline {9.22}1*1卷积}{176}{section.9.22}
\contentsline {section}{\numberline {9.23}目标检测中完整流程}{177}{section.9.23}
\contentsline {section}{\numberline {9.24}Batch Size的影响}{177}{section.9.24}
\contentsline {section}{\numberline {9.25}非极大值抑制NMS}{177}{section.9.25}
\contentsline {section}{\numberline {9.26}Bilinear filler初始化ConvTranspose层的权重}{178}{section.9.26}
\contentsline {section}{\numberline {9.27}卷积层输出的尺寸}{178}{section.9.27}
\contentsline {section}{\numberline {9.28}机器学习面试博客总结2018.06.11}{179}{section.9.28}
\contentsline {subsection}{\numberline {9.28.1}大疆}{179}{subsection.9.28.1}
\contentsline {subsubsection}{机器学习中的范数问题}{179}{section*.224}
\contentsline {subsubsection}{类别中不平衡}{179}{section*.225}
\contentsline {subsubsection}{Confusion Matrix}{179}{section*.226}
\contentsline {subsubsection}{ROC \& AUC}{180}{section*.228}
\contentsline {subsection}{\numberline {9.28.2}机器学习面试总结}{180}{subsection.9.28.2}
\contentsline {section}{\numberline {9.29}花书前两部分总结}{180}{section.9.29}
\contentsline {subsection}{\numberline {9.29.1}第三章}{180}{subsection.9.29.1}
\contentsline {subsubsection}{概率论的知识}{180}{section*.229}
\contentsline {subsubsection}{信息论}{180}{section*.230}
\contentsline {subsubsection}{结构化概率模型}{181}{section*.231}
\contentsline {subsection}{\numberline {9.29.2}第四章}{181}{subsection.9.29.2}
\contentsline {subsubsection}{上溢和下溢}{181}{section*.232}
\contentsline {subsubsection}{病态条件}{182}{section*.233}
\contentsline {subsubsection}{基于梯度的优化方法}{182}{section*.234}
\contentsline {subsubsection}{梯度之上}{182}{section*.235}
\contentsline {subsubsection}{约束优化}{183}{section*.236}
\contentsline {subsection}{\numberline {9.29.3}第五章}{183}{subsection.9.29.3}
\contentsline {subsubsection}{设计矩阵}{183}{section*.237}
\contentsline {subsubsection}{容量、过拟合和欠拟合}{183}{section*.238}
\contentsline {subsubsection}{估计、偏差和方差}{184}{section*.239}
\contentsline {subsubsection}{最大似然估计}{184}{section*.240}
\contentsline {subsubsection}{贝叶斯估计}{185}{section*.241}
\contentsline {subsubsection}{随机梯度下降}{185}{section*.242}
\contentsline {subsubsection}{促使深度学习发展的挑战}{186}{section*.243}
\contentsline {subsection}{\numberline {9.29.4}第六章}{186}{subsection.9.29.4}
\contentsline {subsubsection}{基于梯度的学习}{186}{section*.244}
\contentsline {subsubsection}{隐藏单元}{188}{section*.245}
\contentsline {subsubsection}{架构设计}{191}{section*.247}
\contentsline {subsubsection}{反向传播}{191}{section*.248}
\contentsline {subsection}{\numberline {9.29.5}第七章}{192}{subsection.9.29.5}
\contentsline {subsubsection}{参数范数惩罚}{192}{section*.249}
\contentsline {subsubsection}{数据集增强}{192}{section*.250}
\contentsline {subsubsection}{噪声鲁棒性}{192}{section*.251}
\contentsline {subsubsection}{半监督学习}{193}{section*.252}
\contentsline {subsubsection}{多任务学习}{193}{section*.253}
\contentsline {subsubsection}{提前终止}{193}{section*.254}
\contentsline {subsubsection}{Bagging等集成方法}{193}{section*.255}
\contentsline {subsubsection}{Dropout}{193}{section*.256}
\contentsline {subsubsection}{对抗训练}{193}{section*.257}
\contentsline {subsection}{\numberline {9.29.6}第八章}{193}{subsection.9.29.6}
\contentsline {subsubsection}{神经网络优化中的挑战}{193}{section*.258}
\contentsline {subsubsection}{基本算法}{194}{section*.259}
\contentsline {subsubsection}{参数初始化策略}{196}{section*.260}
\contentsline {subsubsection}{自适应学习率算法}{196}{section*.261}
\contentsline {subsubsection}{选择正确的优化算法}{198}{section*.262}
\contentsline {subsubsection}{优化策略和元算法}{198}{section*.263}
\contentsline {section}{\numberline {9.30}梯度消失-梯度爆炸 专题}{198}{section.9.30}
\contentsline {subsection}{\numberline {9.30.1}自圆其说的解释}{199}{subsection.9.30.1}
\contentsline {section}{\numberline {9.31}ROI Pooling}{199}{section.9.31}
\contentsline {section}{\numberline {9.32}深度学习面试100题}{199}{section.9.32}
\contentsline {subsection}{\numberline {9.32.1}Tensorflow计算图}{199}{subsection.9.32.1}
\contentsline {subsection}{\numberline {9.32.2}DL调参}{200}{subsection.9.32.2}
\contentsline {subsection}{\numberline {9.32.3}为什么CNN在CV、NLP、Sppech、AlphaGo里面都有应用}{200}{subsection.9.32.3}
\contentsline {subsection}{\numberline {9.32.4}为什么要引入非线性激励函数}{201}{subsection.9.32.4}
\contentsline {subsection}{\numberline {9.32.5}为什么ReLU要好于tanh和sigmoid function}{201}{subsection.9.32.5}
\contentsline {subsection}{\numberline {9.32.6}为啥LSTM模型中既存在sigmoid又存在tanh两种激活函数}{201}{subsection.9.32.6}
\contentsline {subsection}{\numberline {9.32.7}如何解决RNN梯度爆炸和弥散问题}{201}{subsection.9.32.7}
\contentsline {subsection}{\numberline {9.32.8}什么样的数据集不适合深度学习}{202}{subsection.9.32.8}
\contentsline {subsection}{\numberline {9.32.9}如何解决梯度消失和梯度膨胀}{202}{subsection.9.32.9}
\contentsline {subsection}{\numberline {9.32.10}激活函数的真正意义}{202}{subsection.9.32.10}
\contentsline {subsection}{\numberline {9.32.11}梯度下降训练神经网络容易收敛到局部最优，为什么还应用广泛}{203}{subsection.9.32.11}
\contentsline {section}{\numberline {9.33}数据的归一化}{203}{section.9.33}
\contentsline {subsection}{\numberline {9.33.1}为什么需要归一化}{203}{subsection.9.33.1}
\contentsline {subsection}{\numberline {9.33.2}归一化的方法}{203}{subsection.9.33.2}
\contentsline {subsection}{\numberline {9.33.3}小结}{204}{subsection.9.33.3}
\contentsline {section}{\numberline {9.34}待续}{204}{section.9.34}
\contentsline {chapter}{\numberline {10}Image Processing}{205}{chapter.10}
\contentsline {section}{\numberline {10.1}Feature Extraction}{205}{section.10.1}
\contentsline {subsection}{\numberline {10.1.1}SIFT}{205}{subsection.10.1.1}
\contentsline {chapter}{\numberline {11}Feature Extraction}{207}{chapter.11}
\contentsline {section}{\numberline {11.1}Selective Search}{207}{section.11.1}
\contentsline {subsection}{\numberline {11.1.1}Efficient Graph-Based Image Segmentation}{207}{subsection.11.1.1}
\contentsline {subsection}{\numberline {11.1.2}Selective Search}{208}{subsection.11.1.2}
\contentsline {section}{\numberline {11.2}Region CNN}{208}{section.11.2}
\contentsline {subsection}{\numberline {11.2.1}概述}{208}{subsection.11.2.1}
\contentsline {subsubsection}{Boundingbox 回归}{208}{section*.265}
\contentsline {section}{\numberline {11.3}SPP Net}{208}{section.11.3}
\contentsline {subsection}{\numberline {11.3.1}背景与相关工作}{208}{subsection.11.3.1}
\contentsline {subsection}{\numberline {11.3.2}网络结构}{209}{subsection.11.3.2}
\contentsline {subsubsection}{Fisher Kernel}{209}{section*.267}
\contentsline {subsubsection}{Convolutional Layers and Feature Maps}{210}{section*.268}
\contentsline {subsubsection}{The Spatial Pyramid Pooling Layer}{210}{section*.269}
\contentsline {subsubsection}{Training}{210}{section*.271}
\contentsline {subsection}{\numberline {11.3.3}Object Detection Experiments}{210}{subsection.11.3.3}
\contentsline {subsection}{\numberline {11.3.4}Conclusion}{211}{subsection.11.3.4}
\contentsline {section}{\numberline {11.4}Fast RCNN}{212}{section.11.4}
\contentsline {subsection}{\numberline {11.4.1}ROI-Pooling层的实现-知乎}{212}{subsection.11.4.1}
\contentsline {subsubsection}{ROI Pooling层}{212}{section*.272}
\contentsline {section}{\numberline {11.5}Faster RCNN}{213}{section.11.5}
\contentsline {section}{\numberline {11.6}R FCN}{213}{section.11.6}
\contentsline {section}{\numberline {11.7}Mask RCNN}{213}{section.11.7}
\contentsline {section}{\numberline {11.8}YOLO}{213}{section.11.8}
\contentsline {section}{\numberline {11.9}YOLO v2}{213}{section.11.9}
\contentsline {section}{\numberline {11.10}YOLO v3}{213}{section.11.10}
\contentsline {section}{\numberline {11.11}SSD}{213}{section.11.11}
\contentsline {section}{\numberline {11.12}DSSD}{213}{section.11.12}
\contentsline {section}{\numberline {11.13}Retina Net (Focal Loss)}{213}{section.11.13}
\contentsline {section}{\numberline {11.14}Feature Pyramid Network}{213}{section.11.14}
\contentsline {subsection}{\numberline {11.14.1}Nearest Neighbor Interpolation}{213}{subsection.11.14.1}
\contentsline {section}{\numberline {11.15}ResNet}{213}{section.11.15}
